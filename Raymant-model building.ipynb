{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score,mean_squared_error,accuracy_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc,classification_report\n",
    "\n",
    "# filtering warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>...</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "      <th>Y8</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>Z6</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>860.62</td>\n",
       "      <td>809.73</td>\n",
       "      <td>919.69</td>\n",
       "      <td>30.87</td>\n",
       "      <td>69.81</td>\n",
       "      <td>65.24</td>\n",
       "      <td>74.10</td>\n",
       "      <td>2.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-3.290000e-08</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>9.150000e-07</td>\n",
       "      <td>1.190000e-07</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>871.58</td>\n",
       "      <td>789.74</td>\n",
       "      <td>929.69</td>\n",
       "      <td>32.82</td>\n",
       "      <td>68.94</td>\n",
       "      <td>64.54</td>\n",
       "      <td>75.97</td>\n",
       "      <td>2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>-3.290000e-08</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>7.880000e-07</td>\n",
       "      <td>1.280000e-07</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>854.87</td>\n",
       "      <td>789.74</td>\n",
       "      <td>929.69</td>\n",
       "      <td>32.38</td>\n",
       "      <td>70.29</td>\n",
       "      <td>64.54</td>\n",
       "      <td>75.97</td>\n",
       "      <td>2.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>-3.290000e-08</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>7.660000e-07</td>\n",
       "      <td>1.150000e-07</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>823.73</td>\n",
       "      <td>759.75</td>\n",
       "      <td>879.71</td>\n",
       "      <td>29.19</td>\n",
       "      <td>72.93</td>\n",
       "      <td>68.20</td>\n",
       "      <td>78.97</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>-3.290000e-08</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>7.330000e-07</td>\n",
       "      <td>9.480000e-08</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>823.44</td>\n",
       "      <td>759.75</td>\n",
       "      <td>879.71</td>\n",
       "      <td>28.98</td>\n",
       "      <td>72.96</td>\n",
       "      <td>68.20</td>\n",
       "      <td>78.97</td>\n",
       "      <td>2.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>-3.290000e-08</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>8.330000e-07</td>\n",
       "      <td>1.010000e-07</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  A       B       C       D      E      F      G      H     I  \\\n",
       "0           0  6  860.62  809.73  919.69  30.87  69.81  65.24  74.10  2.51   \n",
       "1           1  7  871.58  789.74  929.69  32.82  68.94  64.54  75.97  2.65   \n",
       "2           2  6  854.87  789.74  929.69  32.38  70.29  64.54  75.97  2.66   \n",
       "3           3  7  823.73  759.75  879.71  29.19  72.93  68.20  78.97  2.58   \n",
       "4           4  6  823.44  759.75  879.71  28.98  72.96  68.20  78.97  2.56   \n",
       "\n",
       "   ...        Y6        Y7        Y8        Y9            Z1        Z2  \\\n",
       "0  ...  0.002757 -0.003582  0.000125  0.001961 -3.290000e-08  0.000346   \n",
       "1  ...  0.002757 -0.002944  0.000131  0.001932 -3.290000e-08  0.000358   \n",
       "2  ...  0.003168 -0.002944  0.000125  0.001628 -3.290000e-08  0.000339   \n",
       "3  ...  0.003168 -0.002490  0.000116  0.001572 -3.290000e-08  0.000308   \n",
       "4  ...  0.003091 -0.002601  0.000126  0.001596 -3.290000e-08  0.000318   \n",
       "\n",
       "         Z4            Z5            Z6  Class  \n",
       "0  0.000956  9.150000e-07  1.190000e-07      A  \n",
       "1  0.000888  7.880000e-07  1.280000e-07      A  \n",
       "2  0.000875  7.660000e-07  1.150000e-07      A  \n",
       "3  0.000856  7.330000e-07  9.480000e-08      A  \n",
       "4  0.000913  8.330000e-07  1.010000e-07      A  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/INDIAN/Downloads/Test_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is a unnamed feature in dataset which is a duplicate index so,we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping classes (numberic) column into categorical:\n",
    "dow = {\"A\":0, \"B\":1, \"C\":2, \"D\":3 , \"E\":4, \"F\":5}\n",
    "\n",
    "df[\"Class\"] = df[\"Class\"].map(dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining dependent and independent\n",
    "\n",
    "x=df.drop('Class',axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection technique\n",
    "\n",
    "#### 1) using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    1.0\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=df.corr()\n",
    "cor_target=abs(corr['Class'])\n",
    "imp_features=cor_target[cor_target>=0.5]\n",
    "imp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no feature has atleast 50% correlation with the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) recursive feature elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 9\n",
      "Score with 9 features: 0.309361\n"
     ]
    }
   ],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,10)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 0)\n",
    "    model = LogisticRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False  True  True False False False False False False False False\n",
      "  True  True  True False False False False False False  True False  True\n",
      " False False  True  True False]\n",
      "[ 7 25 28 26 19 13 18 17 11 10 14 21 24 20  1  1 27 31 30  8 16 22 23 15\n",
      "  1  1  1  3 32  6  5 29  2  1  9  1 33  4  1  1 12]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "## initialize RFE\n",
    "rfe=RFE(model,9)\n",
    "rfe.fit(x,y)\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by RFE we can see it showing the highest score i.e,30% can be acheived by 9 features.In this case dimensions are reducing but the model is not learning accurately, so it is better to use dimentionality reduction technique-PCA and capture maximum data with minimum no.of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\indian\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (0.13.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (41.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (0.21.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (1.16.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (3.1.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\indian\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\indian\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2019.1)\n",
      "Requirement already satisfied: six in c:\\users\\indian\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "\n",
    "sfs1=sfs(model,k_features=9,forward=True,scoring='r2',cv=3)\n",
    "sfs1=sfs1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3xcdZ34/9d7LpnJrWmhbegNyqWgBQRpaEUQUhEsu0r98YW1iCzs6q+7q4VVxP3CyrLoyrqsykUBtQiCXCyIoF2tsiqkgHIpRW4FkVKgpC290FuSyVzOOe/vH+dMOp1Okpkkk5kk7+fjETLnOu+Zks/7fD6fcz4fUVWMMcaYfKFKB2CMMaY6WYIwxhhTkCUIY4wxBVmCMMYYU5AlCGOMMQVZgjDGGFOQJQhTtUTkCBH5k4h0iMjFlY6nLyLSJiKfrfZzBuf9tYhcMNTnNaNPpNIBGNOHfwHaVPX9lQ5kpBKRq4DDVPXT2XWqekblIjIjidUgTDU7CFgzkANFpCwXP+U6rzHVyBKEqUoi8jAwH7hRRDpF5HARaRKRH4vIVhF5S0SuEJFQsP+FIvIHEblORLYDVwX7zAm2f1pEVERmB8ufFZGfB6/nisgTIrJTRDaJyI0iUpMTi4rI50XkNeC1YN1pIvJnEdklIjcC0sdnmSsiz4jIbhHZLCLX5mz7gIj8MXjv50WktY/z/L2IvCIiO0TkIRE5KGfbkSLyWxHZHrzHv4rIAuBfgU8G3+Hzwb49TVciEgq+x7dEZEvw/TYF22YGn/0CEVkvIttE5Cul/Duakc0ShKlKqvph4DFgiao2qOpfgO8CTcAhwCnA3wJ/l3PYPGAdMBm4GlgJtAbbTg62nZKzvDJ47QJfBCYCJwCnAp/LC+kTwflni8hE4GfAFcExrwMn9vFxbgBuUNVxwKHAfQAiMg34FfB1YD/gUuBnIjIp/wQi8gn8wv4sYFLw3fwk2NYI/A74DTAVOAz4var+BvhP4N7gOzymQGwXBj/z8b/XBuDGvH1OAo4IvpcrReS9fXxWM4pYgjAjgoiEgU8Cl6tqh6q+CXwbOD9nt42q+l1VdVS1Gz8BZBPCh4Bv5CyfEmxHVVer6pPBcW8CP8jZL+sbqro9OO9fAS+r6v2qmgGuB97pI/wMcJiITFTVTlV9Mlj/aWCFqq5QVU9Vfws8E5w/3z8EMbyiqg5+wX9sUIv4GPCOqn5bVZPB9/NUH/HkOg+4VlXXqWoncDmwKK8p7auq2q2qzwPPA4USjRmFLEGYkWIiUAO8lbPuLWBazvLbecesBD4kIgcAYeBe4EQRmYlfE3kOIGi++qWIvCMiu/EL34l558o999TcZfVHvMx/71yfAQ4H/iwiq0TkY8H6g4BzgualnSKyE/9qfUqBcxwE3JCz33b8Zq1pwAz8WsxATGXf7zQCNOesy01+CfxahhkDLEGYkWIb/pX4QTnrDgQ25CzvNTSxqq7FL9AuBh5V1Q78wm4x8LiqesGu3wP+DMwKmoH+lX37FHLPvQm/UAZARCR3OZ+qvqaq5+I3fV0D3C8i9fhJ5U5VHZ/zU6+q/1XgNG8D/5C3b62q/jHYdmhvb99bXIGN7PudOsDmfo4zY4AlCDMiqKqL33Z/tYg0Bk0rlwB39XPoSmAJe/ob2vKWARqB3UCniLwH+Kd+zvkr4EgROStoirkYOKC3nYMO8klBQtoZrHaD2D8uIh8VkbCIxEWkVUSmFzjN94HLReTI4JxNInJOsO2XwAEi8gURiQXfz7xg22ZgZrYzv4CfAF8UkYNFpIE9fRZOP9+BGQMsQZiR5CKgC7+z+XHgHuC2fo5ZiZ8AHu1lGfzO4U8BHcAt+E1RvVLVbcA5wH8B7wKzgD/0ccgCYI2IdOJ3WC8K+greBhbi11i24tcEvkyBv0tVfRC/9rEsaAZ7CTgj2NYBnAZ8HL+G9Bp+pzPAT4Pf74rIswViuw24E//7eANI4n/PxiA2YZAxxphCrAZhjDGmIEsQxhhjCrIEYYwxpiBLEMYYYwoaNQOPTZw4UWfOnDng47u6uqivrx+6gIaIxVUai6s0FldpRmNcq1ev3qaq+wzvAoCqjoqfOXPm6GA88sgjgzq+XCyu0lhcpbG4SjMa4wKe0V7KVWtiMsYYU5AlCGOMMQVZgjDGGFOQJQhjjDEFWYIwxhhTUFkThIgsEJFXRWStiFxWYPvJIvKsiDgicnaB7eNEZEMwpaMxxphhVLYEEcwAdhP+iJOzgXOz8wHnWI8/3eE9vZzmP9h7WGZjjDHDpJw1iLnAWvWnMkwDy/CHNu6hqm+q6guAl39wMNl8M/C/ZYzRGGNML8o23HfQZLRAVT8bLJ8PzFPVJQX2vR34pareHyyHgIfx5xs+FWjp5bjF+LOD0dzcPGfZsmUDjrezs5OGhuqbSdHiKo3FVdg+f+XBity4tPCeex1TTGmhe/9n37P2eh7tOSyVTBCL1xXxbsOrmuMa19g4oGPnz5+/WlVbCm0r51Ab+VM2QnH/fwF8Dn8y97f92RwLU9WlwFKAlpYWbW1tLTXGHm1tbQzm+HKxuEpTDXGpKo6nOK5HxvVwXI9nn/ojRxxzPKrgZZ9UBVSDHxT1FA9QL1jWnN/7HBf87tlX8Xr56xIRsheCEvw3KIrpfv0FGmf4Lb+5h0uwLOK/d89yL/vlv5/stezvmfunLMF+e++zZ1v7q88x7Yj3F/5AFdT+5z9VZVzrX3mWk085hVAf5eVAlDNBtLP3PL3T8ee/LcYJ+JPNfw5/gvQaEelU1X06uo0Zbq7nkXH9BOC4HmnHI5lxSKZdUhmXlOPuVagCpB2PTTsS5BaUuYVkb4Xnnn3F/+MPSbA9u9Y/IL/ALdb2kNBUHyv5uHILCcSi4UqHsQ+p0rjKpZwJYhUwS0QOxp9YfhH+tI79UtXzsq9F5EL8JiZLDqbsPM0W/BoU/q6fANIOyYyfCFxvz9W4AiERwiEhEg4RCYeIRcP7FNbbQ0Jjbc3wfyBjBqFsCUJVHRFZAjwEhIHbVHWNiHwNf3Co5SJyPPAgMAF/8vavquqR5YrJmOxVf7YGkHLc4MrfoTvjknG8fZpNIuEQ4ZCfBOpjUUKhoa3GG1Otyjrct6quAFbkrbsy5/Uq/Kanvs5xO3B7GcIzo5ACXclMT9t/d3Dln8q4JDMO+fdkhER6EkA8GqY+Fq1I3MZUo1EzH4QZ21IZlw3bu+hOObzcvgPw2+TDISESEsLhEI21NUPeiWfMaGYJwoxorqds3Z3g7W1dhEN+TWB8FXa6GjMSWYIwI5KqsiuR5q2tHaQdj8baGsIhYWulAzNmFLEEYUacZNph/bZOdnalqI9HqbN+A2PKwhKEGTEc12PzzgQbdiSIhkNMaIhXOiRjRjVLEKbqqSo7OlOs39aJ43o01dbYrabGDANLEKaqdaUyrN/Wye5EhsZ4lPq4NScZM1wsQZiqlHE9Nm7vYvPOBLFohP0a7M4kY4abJQhTVTxVtnckWb+tE0+hqT5mzy4YUyGWIEzV6ExmeHNLB4lUhsbaGiJhmxHXmEqyBGEqLu24fnPSrm7qaiJ2d5IxVcIShKkY11O27e5m/bZOwiFhQn1sQENWG2PKwxKEqYjdwVPQ3WmXcXVRwiFrTjKm2liCMMMqmXFp39bBu51p6mMRJtjdScZULUsQZli4nsfmXd1seLeLSDhkt60aMwJYgjBlpars7Erx1rZOMo7HOHsK2pgRwxKEKZvutMP6rZ3sSviD6tlkPMaMLJYgzJDLuB7v7EywaXuCWDRst60aM0KV9dYREVkgIq+KyFoRuazA9pNF5FkRcUTk7Jz1x4rIEyKyRkReEJFPljNOMzRUlW0dSV58610270jQVF9DXcyuQYwZqcr21ysiYeAm4DSgHVglIstV9eWc3dYDFwKX5h2eAP5WVV8TkanAahF5SFV3liteMzhdyQxvbe2gK+lQXxslak9BGzPilfPybi6wVlXXAYjIMmAh0JMgVPXNYJuXe6Cq/iXn9UYR2QJMAixBVJnsU9BbdiWJ14QZb3cnGTNqlDNBTAPezlluB+aVehIRmQvUAK8X2LYYWAzQ3NxMW1vbgAIF6OzsHNTx5VLNcf3u94+QdlwAwlVyZ1IqmWDdS89UOox9WFylsbhK46S6eXTlyiE/bzkTRKESQ0s6gcgU4E7gAlX18rer6lJgKUBLS4u2trYOIExfW1sbgzm+XKoxrlTG5ZFH2hh34JFV9xT0upee4ZCjWiodxj6qLa7lD0S59htxNm0UpkxVLrk8yZlnZSodVo9q+76yqjWu115YxcmnnDLkIx+X8y+7HZiRszwd2FjswSIyDvgVcIWqPjnEsZkB8lR5c0sHijKhIVZVycEUZ/kDUa74ci0bN4RQFTZuCHHFl2tZ/kDlb0Ne/kCU1uMbOeOjH6b1+MaqiAmqP66PnXEqB8+Eu+8e2vOXswaxCpglIgcDG4BFwKeKOVBEaoAHgR+r6k/LF6Ip1ZZd3exKpGyOhiLtuVL/8JBfqatCKgmJhJBIQKJL/J/s67z13Qmhqwse/GkNye69//2S3cK//Ustz64KUxODWEyJx/3fNTGIx5VYsNzzO2d9Tc7+sRjE4lDq/yLZxJWNbeMG4Yov1wJUtHYzUuJavx4WL/a3nXfe0LxH2RKEqjoisgR4CAgDt6nqGhH5GvCMqi4XkePxE8EE4OMi8lVVPRL4G+BkYH8RuTA45YWq+ly54jX960plWL+1k3F1MXZUOpgRoFDB8pVLa3lnkzDvBHfvQr27cAGfLdR7Cvlgv64uoTsBnld8KRyLK3V1Snei8PbuBPzml1FSKSGVBMcZ3EVATW4SieUlkbgfTyy2Z3nF8mjBxPXVy+O89Ublaqq3Ly2cUKsxrkQCvvKVEZAgAFR1BbAib92VOa9X4Tc95R93F3BXOWMzpXE9j3Xv7Ka2Jlw1HdLVorMDNm0MBT/COxtCbNwY4le/iJJO7f1dpZLCt66u7fN8NTG/IK+rg7p69X/qYMpUj7p6pbYO6oP1tbX+PvX1Sm2dUlcfLNf5+2W3xWshEvy1tx7fyMYN+/4bTp2mtK3q6Fl2HEin/cIwnYJUSkgm/d+pFKS6g9/B+nSwPtmz3v+82X1SyT3LyaTQ2Smkc86Z6Cr8fXR0hPjut6vvYctqjWv9+qE7lz3FZIrS/m4XqYxLU/3Yuo01lYR3NvkF/6aNId7ZGGLjhj2vN20M0bF778I2FFImNSvpVG9nVZbemdhTqGcTQVCoR8vcvH3J5cm9ajYA8Vq/+StXJOL/1NVl7y0p6R6TkvWeuDweebqjwBHDY/7cRjZu2LemUK1xHXjg0L2HJQjTr51dKd7ZkajqobkH0tbvOLB1s/Rc/b+z0e+wzb7etDHEu9v2/QOcsJ/H1GnKjIM85p7gMGWqx5Rp6v+e6jH5ACUS6ftKvfVUZ8g+e6my30u13cXUV+KqZJfXSIqrrg6uvnro3sMShOlT2nFZt3k3DbXRqp3trbdOxM5OeN+xLpt6Cn3/6j975b9ls+C6e3+m+gZl6jSPA6Z6zD7a6Sn0p0zzmDJVOWCKR7zvFqIexV6pV8KZZ2U486xMVd22Wa2Ja6TENWMG/Od/ypD1P4AlCNMHVWX9Vr8KXRMJVzia3n3r6njBTsSrLqvba11NzC/gp05T5p2YLfw1KPz9n8ZxQxdXtRYs1awaExdUf1yvvbCKBaefylB3D1qCML3a1pHk3c501U3u09kBq56M8MTj/s87m3q7k0S58dYEU4Or//3212FvEqjWgsWYYliCMAV1px3e3NJBU13lHwhKJeFPq8M88XiEJx+P8MJzYVxXiMWV41pcGsd5dOwu1ImonH5G5dr6jRnpLEGYfbie8sbm3dREwhV5Utp1Yc2LYZ54LMITj4dZvSpCKimEQsrRx7r8/59PccJJDse1uMTi+/ZBQPW09RszklmCMPt4Z0cXnUln2O5aUoXXXwvxx8ciPPmHCE8/EWH3Lr+wP/w9Los+neaEkxyO/4BTsI/A2vqNKQ9LEGYvHd0Z2t/tKvuw3RvbpacP4ck/RNiy2a+pTJ/hcfpfZfjgSQ4fOMlh4qTi7r23tn5jhp4lCNMj43q8vnkX9fHokI+1tP1d4ck/RHjyD35fwltv+HdF7T/R4wMnOpxwksMJH3KYcWB5H8YyxhTPEoTp0b6tE9dV6mODv6W1qyvnTqPHIvz5Zf+c9Q3K3A84nHeh32x0+Hu8ij5sZIzpnSUIA8D2jiRbdnczoZ+hNHp7YjmdgueeDfc0G73wpzCOI0RrlDnHu3zx/yY54SSHo45xe8YEMsZUN/tTNaQyLuu27KaxtqbPp6ULPbF82RdqWXpjDevfDJMM7jQ68n0uf/+P/p1Gc453i37y2BhTXSxBjHHZCYDCoRDRcN+3tF77jX2fWHYcYd3aMOf+bZoPnOgw74MO45rKGbExZrhYghjjshMATWjof9jiTRsL1y5cF/7t6/bMgTGjjc0XOYblTgBUjClTC99h1Nt6Y8zIZglijBrIBEAfOSO9zzp7YtmY0csSxBiVnQAoXlNcK6PnwVN/iDJxksfUaR4i/rDYX/9mtz2xbMwoVdYEISILRORVEVkrIpcV2H6yiDwrIo6InJ237QIReS34uaCccY412QmAxtXVFH3M/66I8OorYS779yRtqzr49UMP07aqw5KDMaNY2RKEiISBm4AzgNnAuSIyO2+39cCFwD15x+4H/DswD5gL/LuITChXrGPJQCYA8jy48do4hxzm8tcLLSEYM1aUswYxF1irqutUNQ0sAxbm7qCqb6rqC4CXd+xHgd+q6nZV3QH8FlhQxljHhIFOAPTQryL85c9hlnwxRbh65w0yxgyxciaIacDbOcvtwbpyH2t6kZ0AqLG2+KalbO3h0FkuZ5xptQdjxpJyPgdRqP2i2PshizpWRBYDiwGam5tpa2srOrh8nZ2dgzq+XIYqLlV/EqBQSNhZwnGPrpzMa68ezWWXv8Rbr2zuWZ9KJlj30jODjmuoWVylsbhKU61xOaluHl25csjPW84E0Q7MyFmeDmws4djWvGPb8ndS1aXAUoCWlhZtbW3N36VobW1tDOb4chmKuFxPeXXDDjKuUhcr/p/cdeG+JQ0cdrjLBZ+bQTi855+zWofVtrhKY3GVplrjeu2FVZx8yilDPgpzOZuYVgGzRORgEakBFgHLizz2IeB0EZkQdE6fHqwzA5CdAKiU5ADw6/+JsvYvYT5vfQ/GjEllSxCq6gBL8Av2V4D7VHWNiHxNRM4EEJHjRaQdOAf4gYisCY7dDvwHfpJZBXwtWGdKlJ0AqKm++H4H8GsPN10XY9YRLmd83PoejBmLyjoWk6quAFbkrbsy5/Uq/OajQsfeBtxWzvhGu8FMAPTr5VFefy3MDT/oogLTUhtjqoD96Y9ib2/rxHGVWLS09iHXhRuvi3H4e1w++tdOmaIzxlQ7G811lNrekWRrERMAFbLiF1HWrQ3znaVWexipVBVPFddTPE/x1B/a3X/t3xAo+Dcw7EqkCFYRDgkhEUIh2ev1UHd+mpHBEsQoVOwEQIVkaw9HvNfl9L+y2kM18DzFzSncXU/R4HdvQgKRcIhoOEw8GiYaCVETCREJh4iEhXAoRDgk7H47zBFTJ+B6Hq6nZFyPtOOScTwyrkfG8UinXPLfSvDvOxfxk0d4n4RCyf/vmepjCWKU8VR5o8gJgAr55c+jvPF6mO/eYrWHoebpnoK9r6t6gleKIgKRUCgo7IVoOEwkKOyjYX8k3uzVfrbQzxbYxQiJ0FgbLSp211Nc108k2R/H9YKk4vUklWTGwXE9VEGCVJKbXwrVUMLBb1NdLEGMMlt2JdiVSLFfERMA5XMcuPm6GEfMdjntDKs9lMLzFCe4CndcxfX2Hj3G9ZTO7nSvV/XRcCinoJe9CvpquBIPiRAKS9EXHblNXHv/+Ikk5bg4zp7kkgwST5brKTu7UuX6OANWrXEhhZ8uHixLEKOIPwFQF+OLnAAo3y9/HuWNdWFuvLX/2oPi3yUVktHfnOBlr5Z7EsCewl+CK/1IKEQsGqYhFiZeE/Gv8CNhIkGh+sf2CHMOnVzBTzG8RPxaQSmV2NyE8se3I8yeUX3jcz71drgq43r67UhZ/gYtQYwSuRMADaSq7jj+cw/vme3ykY/2XXvoTGZQ9QvOtOvieF5PJ2c+wS8spOdqmJ6r4mpoVvBUcd09hX+2fT9XOCTEoxHqYxFi0ezVv1/4Z5t/im3SMb3bU0vx+1DqY/03fQ23kEhVxlWu6zNLEKNEdgKgpgHctQTwPw9GeeuNMDcVUXvIOB6xaIijDtyvZ122+cBTP1l5XvaK0MNx97RVZ1wPN2hWSAdX5X5bddDpCQXbq7M1lVAJySW33dzJKfxz3yMUEmKRMHWxCPGg8M82+UTCVvibsc0SxCiwsyvFOzsTA7qlFYK+h+tjvPdIl48s6Lv2kHE84jVhEnmXLH67efZ5i+Kfu8i/HdO/WydIMqpBQlHSjofjeX6icTxSruLq3skF9m4jDgnEohHiNRFi0RDxaND0Ew4RDjp9w9YTb0yvLEGMcNkJgBrjpd/SmrX8Z37t4ebbuvqtqiZSGWZMbGSoxj0ZSFt1VqHk8tTbYY4+aH8r/I0ZAkUnCBGpBQ5U1VfLGI8pQe4EQNHIwApDx4Gbb4hx5NEup/bT96Dq3644oaG0cZ3KpVByCYkQL/HJcWNMYUWVKiLyceA54DfB8rEiUuzIrKZMtnUk2V7iBED5fnF/lPVvhrnoS8l+aw/daZcJ9bGSZqMzxoxcxV52XoU/hehOAFV9DphZnpBMMbrTDm9u6WBc3cDvqMhk4Kbr4xz1Pof5p/X/3EPacZncVDvg9zPGjCzFJghHVXeVNRJTNNdT3ti8m5pIeFDt7L+4P0r7+hAXfSnVb+3BcT2ikRANRTx1a4wZHYotXV4SkU8BYRGZJSLfBf5YxrhMHwY6AVCuTAZuviHOUcc4tH6k/9pDV8qhuanWBm0zZgwpNkFcBBwJpIB7gF3AF8oVlOldR3eGDdsTJU8AlO/B+4qvPYD/UNyEAQzfYYwZuYq6BFXVBPCV4MdUyJ4JgCKDupJPp+H734nzvvc7tJ7af+2hO+3QVB+1u4OMGWOKvYvptyIyPmd5gojYHNHDLDsB0GDvInrwp1Ha3y6+9pBMOzQ31Q3qPY0xI0+xTUwTVXVndkFVdwBjZ+SxKpCdAGjcIDuJ02n43vVxjjnO4eT5/dceXE8Jh0KDupXWGDMyFZsgPBE5MLsgIgex95A5BYnIAhF5VUTWishlBbbHROTeYPtTIjIzWB8VkTtE5EUReUVELi8yzlEpGUwANG4AEwDle+DeGjZuKL72kEhlaB5fa+MRGTMGFXsbzFeAx0VkZbB8MrC4rwNEJAzcBJwGtAOrRGS5qr6cs9tngB2qepiILAKuAT4JnAPEVPVoEakDXhaRn6jqm8V+sNHkzS0dPaOGDkY6Dd+7Icaxcxw+1FrcfA+Op+zfaJ3TxoxFRZU4qvob4DjgXuA+YI6q9tcHMRdYq6rrVDUNLAMW5u2zELgjeH0/cKr4l8gK1ItIBKgF0sDuYmIdbRzXY1ciRX188M8f/GxZDZs2hri4yNpDKuPSEItQW2NDdhkzFkn+2Pe97igyDTiInFqHqj7ax/5nAwtU9bPB8vnAPFVdkrPPS8E+7cHy68A8/Nto7wROBeqAL6rq0gLvsZigJtPc3Dxn2bJlRX2WQjo7O2loaBjw8YOlgOqe8Y6yA9ElEwnitYPvIE6nhb+/8INMmpzk2utWF5UgXE+JRcMFm5cq/X31xuIqjcVVmtEY1/z581erakuhbUVdGopItulnDZCdTkuBXhMEhWfAy89Gve0zF3CBqcAE4DER+Z2qrttrRz9pLAVoaWnR1tbWvj9IH9ra2hjM8X3JzkKWnRMh5bik0i7dGZdU8JM/D0J2HoKNf3mOQ44q+G9XknvuqGHbtjjf/K7LoUf3fz7PUzqSGY6duX/Bpq1yfl+DYXGVxuIqzViLq9i2g08AR6hqKZOxtgMzcpanAxt72ac9aE5qArYDnwJ+o6oZYIuI/AFoAdZRhfYU/n4iSGYckhmXZNov/NOOh8ieeQuycw1Hwv6cxPFouNfO56HoGk6n4PvfiXHc8Q4fPLm4vodE2mHSuPig+z2MMSNXsQliHRDFf5K6WKuAWSJyMLABWIRf8OdaDlwAPAGcDTysqioi64EPi8hd+E1MHwCuL+G9h4wGk9ZkZ0VLO65f+PckAAcvb9Iaf/KcEJGwEK+JUB+v7B1A991TwzubQnzjukTRUxNmHI+J1jltzJhWbIJIAM+JyO/JSRKqenFvB6iqIyJLgIfwpxi7TVXXiMjXgGdUdTlwK3CniKzFrzksCg6/CfgR8BJ+2fsjVX2htI9WPC9o79/ZlSLt+DWA7p6rf9efbzk7HyZ7mn8ioRANtTVVPT5RKgk/uDHGnLkOH/yQW9QxaceltiY8qLGejDEjX7ElwPLgpySqugJYkbfuypzXSfxbWvOP6yy0vlwSKYdk2uW1Tbv2av6Jhvtu/hkJ7runhs2bQvz3DcXXHhIph5mTG0f05zbGDF6xYzHd0f9eI1f2Rq7xA5zTuVplaw8t8xw+cGJxtYfsXW1NdfbktDFjXbF3Mc0CvgHMBnoaplX1kDLFZYbAvXfXsOWdEN/6bvG1h+60y/6NcZs1zhhT9FAbPwK+BzjAfODH+M8pmCqV7IalN8aYe0LxtQeAdMZl0jibNc4YU3yCqFXV3+M/WPeWql4FfLh8YZnBuvfuGrZsDnHRl5JFH5NxPaLREA1x65w2xhTfSZ0UkRDwWnBn0gZsNNeqla09zPugw7wPFl97SCQzTJ/YYJ3Txhig+BrEF/CfR7gYmAOcj//8gqlCy+6qYeuW0moPqooHTBhlHfXGmIEr9i6mVcHLTuDvyheOGazuhF97+MCJDnNPKL72kMy4jK+rIWazxhljAsXexdSCP+R3/mB97ytTXGaAlt1Vw7atIW5YmijpuFTa5aBJjWWKyhgzEhXbB3E38GXgRfYM1meqTHcCbrkpxgknORw/r/jag+t5hMNCwxAMKW6MGT2KTRBbg6ExTBW758d+7UDyt90AABs4SURBVOE7JdYeupIOUybU2axxxpi9FJsg/l1Efgjkj8X0QFmiMiVLJOCHN8f44IcytJRQewC/BrFfg3VOG2P2VmyC+DvgPfgjuubOB2EJokr85I4a3t0W4qIvldj3kHEZV1tD3GaNM8bkKbZUOEZVjy5rJGbAEgm45eYYJ56cYc7c0moP3WmHQ5vHlSkyY8xIVuxzEE+KyOyyRmIG7J7ba9j+boiLLy1lug5/1riQCE31NjCfMWZfxdYgTgIuEJE38PsgBFC7zbXyurr82sOHWjO8v6W02kNXyp81LhyyWeOMMfsqNkEsKGsUZsDu/lENO7aX3vcA4Lgu+4+zWeOMMYX1myCCMZh+papHDUM8pgRdXfDD78X40PwMx84prfaQdlxqYxHqY/bsgzGmsH7bFlTVA54XkQOHIR5Tgrtui7FzR4iLv1Ra3wP4s8ZNGV9XhqiMMaNFsY3PU4A1IvJ7EVme/envIBFZICKvishaEbmswPaYiNwbbH9KRGbmbHufiDwhImtE5EURsbaQHJ2dcOv3azj5wxmOOa602oOXnTXOBuYzxvSh2D6Ir5Z6YhEJAzcBpwHtwCoRWa6qL+fs9hlgh6oeJiKLgGuAT4pIBLgLOF9VnxeR/YFMqTGMZnf9yK89DKTvIZFymDguTjRsndPGmN4VVUKo6krgz0Bj8PNKsK4vc4G1qrpOVdPAMmBh3j4Lgex81/cDp4o/GcHpwAuq+nzw/u+qammXyaNYZwfc9v0aWj+S4Zj3l/61ZBzPZo0zxvSrqAQhIn8DPA2cA/wN8JSInN3PYdOAt3OW24N1BfdRVQfYBewPHA6oiDwkIs+KyL8UE+dYcWfQ97DkktL7HjKOR7wmTH3Mnpw2xvSt2FLiK8DxqroFQEQmAb/Dv+rvTaGR37TIfSL4z14cDySA34vI6mDa0z0HiywGFgM0NzfT1tbW/ycpwFPFSXWz7qVnBnR8OaWSib3i6uoKc8vNJzJv3lYaIi+w7qXSzud6Sk0kxMo3Bte81NnZOeDvu5wsrtJYXKUZa3EVmyBC2eQQeJf+ax/twIyc5enAxl72aQ/6HZqA7cH6laq6DUBEVgDH4Q8W2ENVlwJLAVpaWrS1tbXIj7O3ju4Mjz26kkOOahnQ8eW07qVn9orr5utjdHZE+b9fjZccr6qyK5HmmJn7UxMZ3MRAbW1tDPT7LieLqzQWV2nGWlzFXkb+JmjuuVBELgR+Bazo55hVwCwROVhEaoBFQP6dT8vZM3Xp2cDDqqrAQ8D7RKQuSBynAC8zxnXshtt+EOPU0zMc9b7Sp+XoTrtMqI8NOjkYY8aGPmsQIhJT1ZSqfllEzsJv9hFgqao+2NexquqIyBL8wj4M3Kaqa0Tka8AzwfwStwJ3isha/JrDouDYHSJyLX6SUWCFqv5qcB915PvxrTF27xKWXFL8XNO5UhmXgyfbrHHGmOL018T0BHCciNypqudT4vDeqrqCvJqGql6Z8zqJ3/Fd6Ni78G91NcDuXfCjpTFO/WiGIwdQe3Bcj2g4REOtPTltjClOfwmiRkQuAD4Y1CD2YhMGDZ87fujXHi4aYO2hK+Uwbb86QmKzxhljitNfgvhH4DxgPPDxvG02YdAw2b0Lbr8lxkcWZJh99MCmBPc8ZUKDPYxujClenwlCVR8XkT8C7ap69TDFZPLcfkuMjt3CRV8aWO2hO+3QVB8lHrXOaWNM8YodrO9jwxCLKaCjI8Ltt8Q4/a8yvPfIgdUekmmH5iYbmM8YU5pib3P9XxH5P8EwGGYYPfjAgXR2DPzOJddTwqEQjbU2a5wxpjTFPih3CVAPuCLSzZ4Z5Wwy4zJZ/kCUb10d551N44jXKn/5c5j3zC69BpFIZZg8vpZwyHK7MaY0RSUIVbWb54fR8geiXPHlWpLdfqGe7IYrvuwPrnfmWaUNaut4yv7WOW2MGYBiB+sTEfm0iPxbsDxDROaWN7Sx69v/Ge9JDlnJbuHab5RW0KcyLg2xCHU2MJ8xZgCK7YO4GTgB+FSw3Ik/14MZQokE3HJTDZs2Fm4O6m19r+dLOTTbrHHGmAEq9tJynqoeJyJ/gp6hMKzXc4ikknDvXTV8/7sxtm0NEYspqQIjeU+Zmj8Ybu88TwmFoKnO/pmMMQNTbA0iE8wQp9Az3PfA7rk0PTIZWHZXlNNObOTrV9Zy2OEeP/l5J1d/u5t47d7JIF6rXHJ58XcyJdIOk8bVErFZ44wxA1RsDeI7wIPAZBG5Gn/k1SvKFtUo57p+R/SN18Z4+60w75/jcM0NCU44yZ8dbs5c//e134izaaMwZaqfHErpoM44HhMbrXPaGDNwxd7FdLeIrAZOxb/F9ROq+kpZIxuFPA9+/T9RvvvtGOvWhjnyaJdb7uri5PkO+U+YnHlWhjPPyuwzH0Qx0o5LbU3YOqeNMYPS33DfcfzxmA4DXgR+EEwNakqgCr9/KMIN34rz6sthZh3hcuOtXZy2YN/EMBQSKYeZkxux5xqNMYPR3yXmHUAGeAw4A3gv8IVyBzVaqMLjKyNcd02Ml56PMPMQl2tvSnDGmRnCZRoWyZ9vyTqnjTGD11+CmK2qRwOIyK3A0+UPaXR4+okw110TZ/XTEaZN9/jGtQkWnp0hUuZWn+60y36NcZs1zhgzaP0VVz29osEMcWUOZ+R7bnWY6/87xh8fizL5AI+rvtHN2eemqRmmC/p0xmVSsz34bowZvP4SxDEisjt4LUBtsGxjMeV5+cUQN3wzziO/i7Lf/h7/+tVuFn06Tbx2+GLIuB7RaIiGuM0aZ4wZvP7mg7B2in689mqI73wrzkO/itI03uNLlyf59N+nqK8f/lgSyQzTJzbYrHHGmCFR1qeoRGSBiLwqImtF5LIC22Micm+w/SkRmZm3/UAR6RSRS8sZ50C8uS7EpUtq+diHG3h8ZYQllyR5+MkO/uGiyiQHVcVTmFAfG/43N8aMSmXrMg2evL4JOA1oB1aJyHJVfTlnt88AO1T1MBFZBFwDfDJn+3XAr8sV40BsaBduui7Og/dFiUbhs59L8dl/SjNhv+KHwSiHZMZlfH0NMZs1zhgzRMp5T81cYK2qrgMQkWXAQiA3QSwErgpe3w/cKCKiqioinwDWAV1ljLFom98Rvv+dGPfdXQMCn/67NIuXpJg0ubKJISuVdjloknVOG2OGjmTvmx/yE4ucDSxQ1c8Gy+fjD/q3JGefl4J92oPl14F5QDfwO/zax6VAp6p+q8B7LAYWAzQ3N89ZtmzZgGL1VOns6CRWu+/Ipzt3RvnpfQfxP8un47rCRxds5Nxz32TS5AKj6ZVBKpkgFu97RFbF/wx1NcP35HRnZycNDQ3D9n7FsrhKY3GVZjTGNX/+/NWqWnC4hnKWKIV6SvOzUW/7fBW4TlU7+7q1VlWXAksBWlpatLW1dUCBdnRneOzRlXsNabFrJ9z2gxh33BIjmYSFZ2f4/BeTHHhQI3D0gN5nIIoZamN3Is2UCXVM3W/4Oj/a2toY6PddThZXaSyu0oy1uMqZINqBGTnL04GNvezTLiIRoAnYjl+LOFtE/hsYD3giklTVG4c6yLvvhssvj9DefipTpiqf+2KSrZtD3PaDGB27hb9emGbJJSkOnVW9g9e6nsd+DdY5bYwZWuVMEKuAWSJyMLABWMSeCYeylgMXAE/gjxD7sPptXh/K7iAiV+E3MZUlOSxeDImEX0vZuEG44tJaQPjIggwXX5oc0DzQwymVcWmsrSE+jM1LxpixoWylSvDk9RLgISAM3Kaqa0Tka8AzqrocuBW4U0TW4tccFpUrnkK+8hV/Fre9CRMne9x82z4bqlJ32uHQZnte0Rgz9Mp62amqK4AVeeuuzHmdBM7p5xxXlSU4YP36wuvf3ToyHjTzPCUkQlO9DcxnjBl6Y3q6sQMPLLy+lKk9K6kr5TBpXJxwaEz/MxpjymRMlyxXXw11eXeQljq1ZyU5rsv+42zWOGNMeYzpBHHeebB0KcyYoYgoU6d5fP2b3SVN7VkpacelNhahPmYD8xljymPM3/py3nlw5lkOjz26klnvO77S4RQtkcpw8GTrnDbGlM+YrkGMVJ4qIDTZwHzGmDKyBDECJVIOE8fFiYbtn88YUz5WwoxAGcdj0rhhnInIGDMmWYIYYTKOR7wmTH1szHcfGWPKzBLECJNIZWhuqsXmBzfGlJsliBFEVVFggg3MZ4wZBpYgRpDutMuE+hg1EZs1zhhTfpYgRpBUxmVyk3VOG2OGhyWIEcJxPaLhEA219uS0MWZ4WIIYIbpSDgdMqCVkndPGmGFiCWKE8DxlQoMNzGeMGT6WIEaA7rRDU32UeNQ6p40xw8cSxAiQTDs0N9X1v6MxxgwhSxBVToFwKERjrc0aZ4wZXmVNECKyQEReFZG1InJZge0xEbk32P6UiMwM1p8mIqtF5MXg94fLGWc181SZPL6WcMg6p40xw6tsCUJEwsBNwBnAbOBcEZmdt9tngB2qehhwHXBNsH4b8HFVPRq4ALizXHFWPYX9rXPaGFMB5axBzAXWquo6VU0Dy4CFefssBO4IXt8PnCoioqp/UtWNwfo1QFxExtz4EomUQygk1NnAfMaYChBVLc+JRc4GFqjqZ4Pl84F5qrokZ5+Xgn3ag+XXg3225Z3nH1X1IwXeYzGwGKC5uXnOsmXLBhSrp0pnRyex2urpCPaCfxcnlaSxsaHC0eyrs7OThgaLq1gWV2ksrtIMJq758+evVtWWQtvKeWlaqNE8Pxv1uY+IHInf7HR6oTdQ1aXAUoCWlhZtbW0dUKAd3Rkee3QlhxxV8Dsadh3daaKREIdPGc8Tf3iMgX6ucmpra7O4SmBxlcbiKk254ipnE1M7MCNneTqwsbd9RCQCNAHbg+XpwIPA36rq62WMs6rs6kpRG4vwnmkTiNlzD8aYCipnglgFzBKRg0WkBlgELM/bZzl+JzTA2cDDqqoiMh74FXC5qv6hjDFWDVVlR2eKproaDp/SZNOJGmMqrmylkKo6wBLgIeAV4D5VXSMiXxORM4PdbgX2F5G1wCVA9lbYJcBhwL+JyHPBz+RyxVppnio7u1JMbopz6JQmwiFLDsaYyivr7TGqugJYkbfuypzXSeCcAsd9Hfh6OWOrFp6n7EykmLZfPdP2q7eZ4owxVcPun6wg1/PY1ZXmoMkNHDC+vtLhGGPMXixBVEjG9ejoTnPolCYmNtqDcMaY6mMJogLSjktXyuGIqeMZXz/mnv8zxowQliCGWTLtkHY8Zk+fQEPcZoczxlQvSxDDKJFyUFXeO32CDZ9hjKl6VkoNk47uDNGwcLg9AGeMGSEsQQyDXV0p6mIRDpvSRE3EkoMxZmSwBFFGqsquRJrxdTUccsA4ewDOGDOiWIIoE0+VXV0pJo2r5cBJjTbhjzFmxLEEUQae5w+dMXW/eqbvb09HG2NGJksQQ8z1PHYl0hw4qYEDxtdZcjDGjFiWIIZQz9PRzeOYOK620uEYY8ygWIIYItmnow+f0sQEm0PaGDMKWIIYAsm0Q8pxee+0CTTW2tPRxpjRwRLEIGWfjp49fT97OtoYM6pYiTYI2aejZ02bQNyejjbGjDKWIAZodyJNbU3Yno42xoxaliBK5D8dnaKpLsYhzeOI2NzRxphRyhJECVSVHcHT0QfZ09HGmFGurJe/IrJARF4VkbUiclmB7TERuTfY/pSIzMzZdnmw/lUR+Wg54yyG5yk7OlNMmVDHzMmWHIwxo1/ZEoSIhIGbgDOA2cC5IjI7b7fPADtU9TDgOuCa4NjZwCLgSGABcHNwvopwPWVnIsWBkxqYsX8DIXs62hgzBpSzBjEXWKuq61Q1DSwDFubtsxC4I3h9P3Cq+GNTLASWqWpKVd8A1gbnG3YZ12NXV4pDmscxZYKNq2SMGTtEVctzYpGzgQWq+tlg+XxgnqouydnnpWCf9mD5dWAecBXwpKreFay/Ffi1qt6f9x6LgcUAzc3Nc5YtWzagWD1VOjs6idXW7bVe8ZuWYtFwxZqUOjs7aWhoqMh798XiKo3FVRqLqzSDiWv+/PmrVbWl0LZydlIXKlHzs1Fv+xRzLKq6FFgK0NLSoq2trSWG6OvozvDYoys55Kg931Eq49KddnhPhZ+ObmtrY6Cfq5wsrtJYXKWxuEpTrrjK2cTUDszIWZ4ObOxtHxGJAE3A9iKPLZtEyiHjuhw5Yz8bOsMYM2aVM0GsAmaJyMEiUoPf6bw8b5/lwAXB67OBh9Vv81oOLArucjoYmAU8XcZYe3QmM4jAe23oDGPMGFe2ElBVHRFZAjwEhIHbVHWNiHwNeEZVlwO3AneKyFr8msOi4Ng1InIf8DLgAJ9XVbdcsWbZ09HGGLNHWS+RVXUFsCJv3ZU5r5PAOb0cezVwdTnjy3s/Gmuj9nS0McYErA0FiIaFaCTMoQc02QNwxhgTsEtlIF4ToSYSsuRgjDE5LEEYY4wpyBKEMcaYgixBGGOMKcgShDHGmIIsQRhjjCnIEoQxxpiCLEEYY4wpyBKEMcaYgso2H8RwE5GtwFuDOMVEYNsQhTOULK7SWFylsbhKMxrjOkhVJxXaMGoSxGCJyDO9TZpRSRZXaSyu0lhcpRlrcVkTkzHGmIIsQRhjjCnIEsQeSysdQC8srtJYXKWxuEozpuKyPghjjDEFWQ3CGGNMQZYgjDHGFDTmE4SI3CYiW0TkpUrHkiUiM0TkERF5RUTWiMg/VzomABGJi8jTIvJ8ENdXKx1TLhEJi8ifROSXlY4lS0TeFJEXReQ5EXmm0vFkich4EblfRP4c/H92QqVjAhCRI4LvKvuzW0S+UAVxfTH4f/4lEfmJiMQrHROAiPxzENOacnxPY74PQkROBjqBH6vqUZWOB0BEpgBTVPVZEWkEVgOfUNWXKxyXAPWq2ikiUeBx4J9V9clKxpUlIpcALcA4Vf1YpeMBP0EALapaVQ9XicgdwGOq+kMRqQHqVHVnpePKJSJhYAMwT1UH8xDsYOOYhv//+mxV7RaR+4AVqnp7pWIK4joKWAbMBdLAb4B/UtXXhuo9xnwNQlUfBbZXOo5cqrpJVZ8NXncArwDTKhsVqK8zWIwGP1VxhSEi04G/Bn5Y6ViqnYiMA04GbgVQ1XS1JYfAqcDrlUwOOSJArYhEgDpgY4XjAXgv8KSqJlTVAVYC/99QvsGYTxDVTkRmAu8HnqpsJL6gGec5YAvwW1WtiriA64F/AbxKB5JHgf8VkdUisrjSwQQOAbYCPwqa5H4oIvWVDqqARcBPKh2Eqm4AvgWsBzYBu1T1fysbFQAvASeLyP4iUgf8FTBjKN/AEkQVE5EG4GfAF1R1d6XjAVBVV1WPBaYDc4NqbkWJyMeALaq6utKxFHCiqh4HnAF8PmjSrLQIcBzwPVV9P9AFXFbZkPYWNHudCfy0CmKZACwEDgamAvUi8unKRgWq+gpwDfBb/Oal5wFnKN/DEkSVCtr4fwbcraoPVDqefEGTRBuwoMKhAJwInBm09y8DPiwid1U2JJ+qbgx+bwEexG8vrrR2oD2n9nc/fsKoJmcAz6rq5koHAnwEeENVt6pqBngA+GCFYwJAVW9V1eNU9WT8pvIh638ASxBVKegMvhV4RVWvrXQ8WSIySUTGB69r8f9w/lzZqEBVL1fV6ao6E79Z4mFVrfgVnojUBzcZEDThnI7fLFBRqvoO8LaIHBGsOhWo6A0QBZxLFTQvBdYDHxCRuuBv81T8fsGKE5HJwe8DgbMY4u8sMpQnG4lE5CdAKzBRRNqBf1fVWysbFScC5wMvBu39AP+qqisqGBPAFOCO4O6SEHCfqlbNLaVVqBl40C9TiAD3qOpvKhtSj4uAu4OmnHXA31U4nh5Be/ppwD9UOhYAVX1KRO4HnsVvwvkT1TPkxs9EZH8gA3xeVXcM5cnH/G2uxhhjCrMmJmOMMQVZgjDGGFOQJQhjjDEFWYIwxhhTkCUIY4wxBVmCMFVPRFREvp2zfKmIXDVE575dRM4einP18z7nBKOmPpK3fqaIdOeNYFozgPPPFJFPDV3ExliCMCNDCjhLRCZWOpBcwfMgxfoM8DlVnV9g2+uqemzOT3oA4cwESk4QJX4GM8ZYgjAjgYP/YNIX8zfk1wBEpDP43SoiK0XkPhH5i4j8l4icF8xn8aKIHJpzmo+IyGPBfh8Ljg+LyDdFZJWIvCAi/5Bz3kdE5B7gxQLxnBuc/yURuSZYdyVwEvB9EflmMR84eAr7tuD9/yQiC4P1M4NYnw1+skM+/BfwoaAG8kURuVBEbsw53y9FpDX7HYnI10TkKeAEEZkTfFerReQh8YebR0QuFpGXg8+/rJi4zSijqvZjP1X9gz9fxzjgTaAJuBS4Kth2O3B27r7B71ZgJ/7T3zH8eQW+Gmz7Z+D6nON/g3+xNAt/nKI4sBi4ItgnBjyDP1hbK/7gdgcXiHMq/rAMk/CfnH4Yfx4P8MetailwzEygG3gu+LkpWP+fwKeD1+OBvwD1+ENNx4P1s4Bncj7vL3POeyFwY87yL4HW4LUCfxO8jgJ/BCYFy58EbgtebwRi2Rgq/f+B/Qz/z5gfasOMDKq6W0R+DFyMX6AWY5WqbgIQkdeB7BDNLwK5TT33qaoHvCYi64D34I+b9L6c2kkTfoGcBp5W1TcKvN/xQJuqbg3e8278eRd+3k+cr6s/Qm6u0/EHILw0WI4DB+IX2jeKyLGACxzez7kLcfEHggQ4AjgK+G0wJEgYf0hrgBfwh+P4eRGfwYxCliDMSHI9/ng4P8pZ5xA0lQYDqeV28KZyXns5yx57/7+fP96MAgJcpKoP5W4Immm6eolP+v0ExRPg/6jqq3nvfxWwGTgG/3Mnezm+53sJ5E6RmVRVN+d91qhqoSlH/xo/wZ0J/JuIHKn+xDRmjLA+CDNiqOp24D78Dt+sN4E5weuF+E0mpTpHREJBv8QhwKvAQ8A/BcOuIyKHS/+T6jwFnCIiE4PO33PxZ/kaiIeAi4Kkh4i8P1jfBGwKajzn41/xA3QAjTnHvwkcG3yuGfQ+zPirwCQJ5qQWkaiIHCkiIWCGqj6CPxHTeKBhgJ/FjFBWgzAjzbeBJTnLtwC/EJGngd/T+9V9X17FL8ibgX9U1aSI/BC/f+DZoJDeCnyir5Oo6iYRuRx4BP/KfIWq/mIA8QD8B36N6YXg/d8EPgbcjD+C5znB+2Q/7wuAIyLP4/erXA+8gd+c9hJ+zatQzOmgGe07ItKEXyZcj9/ncVewToDrtDqnJTVlZKO5GmOMKciamIwxxhRkCcIYY0xBliCMMcYUZAnCGGNMQZYgjDHGFGQJwhhjTEGWIIwxxhT0/wDJpAVx+H5jHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plot_sfs(sfs1.get_metric_dict())          #in forward it shows which are true in graph\n",
    "plt.title('forward selection')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', 'C', 'Y1', 'Y3', 'Y8', 'Z1', 'Z4', 'Z5', 'Z6')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_names_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see even forward selection (sequential feature selection) perform very poor .\n",
    "\n",
    "### DIMENTIONALITY REDUCTION USING PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Normalize the data\n",
    "\n",
    "- First step is to normalize the data that we have so that PCA works properly.\n",
    "- This is done by subtracting the respective means from the numbers in the respective column.\n",
    "- So if we have two dimensions X and Y, all X become ùîÅ- and all Y become ùíö-. This produces a dataset whose mean is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix \n",
      "%s [[ 1.00017129 -0.489225   -0.43917033 ...  0.0984491   0.04749056\n",
      "   0.04225471]\n",
      " [-0.489225    1.00017129  0.87439685 ... -0.26537743 -0.06508865\n",
      "  -0.07207115]\n",
      " [-0.43917033  0.87439685  1.00017129 ... -0.30246633 -0.08184475\n",
      "  -0.08488137]\n",
      " ...\n",
      " [ 0.0984491  -0.26537743 -0.30246633 ...  1.00017129  0.7879122\n",
      "   0.75117334]\n",
      " [ 0.04749056 -0.06508865 -0.08184475 ...  0.7879122   1.00017129\n",
      "   0.92762088]\n",
      " [ 0.04225471 -0.07207115 -0.08488137 ...  0.75117334  0.92762088\n",
      "   1.00017129]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(X_std.T)\n",
    "print('Covariance Matrix \\n%s', cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Vectors \n",
      "%s [[ 1.13382303e-01+0.00000000e+00j -5.14606009e-02+0.00000000e+00j\n",
      "  -6.89898462e-02+0.00000000e+00j ...  6.87385909e-16-1.05492237e-15j\n",
      "   6.87385909e-16+1.05492237e-15j  0.00000000e+00+0.00000000e+00j]\n",
      " [-2.35312311e-01+0.00000000e+00j  1.12377090e-01+0.00000000e+00j\n",
      "   8.08740888e-02+0.00000000e+00j ...  1.40952606e-14-2.09212078e-14j\n",
      "   1.40952606e-14+2.09212078e-14j  0.00000000e+00+0.00000000e+00j]\n",
      " [-2.30461415e-01+0.00000000e+00j  1.18898701e-02+0.00000000e+00j\n",
      "   1.87151653e-01+0.00000000e+00j ... -1.66980949e-14+2.82166240e-14j\n",
      "  -1.66980949e-14-2.82166240e-14j  0.00000000e+00+0.00000000e+00j]\n",
      " ...\n",
      " [ 2.14433985e-01+0.00000000e+00j  1.65076171e-01+0.00000000e+00j\n",
      "   1.98373252e-01+0.00000000e+00j ... -1.27231507e-15+1.47601723e-15j\n",
      "  -1.27231507e-15-1.47601723e-15j  0.00000000e+00+0.00000000e+00j]\n",
      " [ 1.35325913e-01+0.00000000e+00j  1.31030596e-01+0.00000000e+00j\n",
      "   2.52911617e-01+0.00000000e+00j ... -5.28514404e-15+7.31123228e-15j\n",
      "  -5.28514404e-15-7.31123228e-15j  0.00000000e+00+0.00000000e+00j]\n",
      " [ 1.41745472e-01+0.00000000e+00j  1.28136636e-01+0.00000000e+00j\n",
      "   2.72257869e-01+0.00000000e+00j ...  6.27284769e-15-8.68209497e-15j\n",
      "   6.27284769e-15+8.68209497e-15j  0.00000000e+00+0.00000000e+00j]]\n",
      "\n",
      " Eigen Values \n",
      "%s [ 1.07869272e+01+0.00000000e+00j  9.23566245e+00+0.00000000e+00j\n",
      "  4.82745216e+00+0.00000000e+00j  3.18277939e+00+0.00000000e+00j\n",
      "  1.70292957e+00+0.00000000e+00j  1.54120819e+00+0.00000000e+00j\n",
      "  1.28763742e+00+0.00000000e+00j  9.81510324e-01+0.00000000e+00j\n",
      "  8.87786585e-01+0.00000000e+00j  7.82367197e-01+0.00000000e+00j\n",
      "  6.76506678e-01+0.00000000e+00j  5.88939756e-01+0.00000000e+00j\n",
      "  5.66269205e-01+0.00000000e+00j  4.38523075e-01+0.00000000e+00j\n",
      "  3.92690498e-01+0.00000000e+00j  3.64934824e-01+0.00000000e+00j\n",
      "  3.25753098e-01+0.00000000e+00j  2.75938706e-01+0.00000000e+00j\n",
      "  2.53104088e-01+0.00000000e+00j  1.84436808e-01+0.00000000e+00j\n",
      "  1.28022404e-01+0.00000000e+00j  1.22572716e-01+0.00000000e+00j\n",
      "  9.46646540e-02+0.00000000e+00j  1.00291743e-01+0.00000000e+00j\n",
      "  7.77569543e-02+0.00000000e+00j  5.82322993e-02+0.00000000e+00j\n",
      "  4.02205379e-02+0.00000000e+00j  3.03718892e-02+0.00000000e+00j\n",
      "  2.19109085e-02+0.00000000e+00j  1.87185942e-02+0.00000000e+00j\n",
      "  9.53878563e-03+0.00000000e+00j  7.02569725e-03+0.00000000e+00j\n",
      "  5.79313195e-03+0.00000000e+00j  3.90826205e-03+0.00000000e+00j\n",
      "  3.81101291e-03+0.00000000e+00j  6.54866268e-04+0.00000000e+00j\n",
      "  2.83983471e-09+0.00000000e+00j -1.86752173e-16+0.00000000e+00j\n",
      "  1.00733627e-17+5.70274699e-18j  1.00733627e-17-5.70274699e-18j\n",
      "  0.00000000e+00+0.00000000e+00j]\n"
     ]
    }
   ],
   "source": [
    "print('Eigen Vectors \\n%s', eig_vecs)\n",
    "print('\\n Eigen Values \\n%s', eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_pairs = [(np.abs(eig_vals[i]), eig_vecs[ :, i]) for i in range(len(eig_vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Variance Explained [ 26.96269946+0.00000000e+00j  50.04790128+0.00000000e+00j\n",
      "  62.11446477+0.00000000e+00j  70.07005052+0.00000000e+00j\n",
      "  74.32664533+0.00000000e+00j  78.17900593+0.00000000e+00j\n",
      "  81.39754818+0.00000000e+00j  83.85090375+0.00000000e+00j\n",
      "  86.06999011+0.00000000e+00j  88.02557312+0.00000000e+00j\n",
      "  89.71655017+0.00000000e+00j  91.1886474 +0.00000000e+00j\n",
      "  92.60407796+0.00000000e+00j  93.7001979 +0.00000000e+00j\n",
      "  94.68175601+0.00000000e+00j  95.59393682+0.00000000e+00j\n",
      "  96.40818009+0.00000000e+00j  97.09790871+0.00000000e+00j\n",
      "  97.73056057+0.00000000e+00j  98.19157362+0.00000000e+00j\n",
      "  98.51157482+0.00000000e+00j  98.81795413+0.00000000e+00j\n",
      "  99.06864054+0.00000000e+00j  99.30526165+0.00000000e+00j\n",
      "  99.49962074+0.00000000e+00j  99.64517656+0.00000000e+00j\n",
      "  99.74571068+0.00000000e+00j  99.8216274 +0.00000000e+00j\n",
      "  99.87639529+0.00000000e+00j  99.92318376+0.00000000e+00j\n",
      "  99.94702664+0.00000000e+00j  99.96458788+0.00000000e+00j\n",
      "  99.97906823+0.00000000e+00j  99.98883721+0.00000000e+00j\n",
      "  99.99836311+0.00000000e+00j  99.99999999+0.00000000e+00j\n",
      " 100.        +0.00000000e+00j 100.        +1.42544258e-17j\n",
      " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
      " 100.        +0.00000000e+00j]\n"
     ]
    }
   ],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [( i /tot ) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(\"Cumulative Variance Explained\", cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can see at 16 components we are capturing 95.5% of the data so,further taking 16 features after applying pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(16)\n",
    "X_train_2 = pca.fit_transform(X_train)\n",
    "X_test_2 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27932354, 0.22946302, 0.1269896 , 0.07712056, 0.04676104,\n",
       "       0.032831  , 0.02434242, 0.02301201, 0.02220123, 0.01926934,\n",
       "       0.01664303, 0.01463371, 0.01252935, 0.01097625, 0.00976616,\n",
       "       0.00937306])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variability explained by each variable\n",
    "explained_variance = pca.explained_variance_ratio_  \n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13382303e-01+0.j, -5.14606009e-02+0.j, -6.89898462e-02+0.j,\n",
       "         1.85301937e-01+0.j,  1.59904755e-01+0.j,  8.18145425e-02+0.j,\n",
       "         3.27882276e-01+0.j, -1.21406601e-01+0.j,  1.71430476e-01+0.j,\n",
       "         6.67402005e-01+0.j,  1.55409981e-01+0.j, -1.51662080e-02+0.j,\n",
       "         1.70741766e-01+0.j, -1.25841306e-01+0.j, -2.85909523e-01+0.j,\n",
       "        -2.73554560e-01+0.j],\n",
       "       [-2.35312311e-01+0.j,  1.12377090e-01+0.j,  8.08740888e-02+0.j,\n",
       "        -2.45694106e-01+0.j, -3.33505700e-02+0.j, -1.47267313e-02+0.j,\n",
       "         3.76843760e-02+0.j, -3.15802294e-04+0.j, -9.68977018e-02+0.j,\n",
       "         4.40498060e-02+0.j, -1.46660323e-02+0.j,  1.16112122e-02+0.j,\n",
       "         1.04144640e-02+0.j,  9.13593605e-02+0.j, -2.34520336e-02+0.j,\n",
       "        -3.22168599e-02+0.j],\n",
       "       [-2.30461415e-01+0.j,  1.18898701e-02+0.j,  1.87151653e-01+0.j,\n",
       "        -2.30208738e-01+0.j, -9.22491153e-02+0.j, -1.65502907e-02+0.j,\n",
       "         8.28224074e-02+0.j,  2.85763650e-03+0.j, -5.76866777e-02+0.j,\n",
       "         9.76097852e-02+0.j, -1.57267671e-01+0.j,  6.26251066e-02+0.j,\n",
       "         3.81493719e-02+0.j, -3.96320760e-03+0.j, -3.46445720e-02+0.j,\n",
       "        -6.58253032e-02+0.j],\n",
       "       [-1.66806448e-01+0.j,  2.34771729e-01+0.j, -4.33697532e-02+0.j,\n",
       "        -1.87461821e-01+0.j, -1.61352424e-02+0.j, -1.80738971e-02+0.j,\n",
       "        -3.72622379e-03+0.j, -1.26611065e-02+0.j, -9.12592373e-02+0.j,\n",
       "         4.96036972e-02+0.j, -7.91993033e-02+0.j,  1.01684741e-01+0.j,\n",
       "         7.54474091e-02+0.j,  1.20097011e-01+0.j, -3.69870443e-02+0.j,\n",
       "        -3.76778942e-02+0.j],\n",
       "       [ 7.21299112e-03+0.j,  2.65253759e-01+0.j, -2.34129908e-01+0.j,\n",
       "        -7.62296727e-02+0.j,  6.57260285e-02+0.j,  6.35737925e-03+0.j,\n",
       "        -1.11643308e-01+0.j, -1.84608811e-02+0.j, -5.42296613e-02+0.j,\n",
       "        -4.75626275e-02+0.j,  1.45801102e-01+0.j, -1.63723855e-02+0.j,\n",
       "         2.16523999e-02+0.j,  7.57934009e-02+0.j, -2.19299062e-02+0.j,\n",
       "        -1.73760790e-02+0.j],\n",
       "       [ 2.40912748e-01+0.j, -7.73713760e-02+0.j, -8.33039495e-02+0.j,\n",
       "         2.52333180e-01+0.j,  1.31945016e-02+0.j,  5.41100563e-03+0.j,\n",
       "         4.90760159e-02+0.j,  2.15883948e-02+0.j,  1.08114033e-01+0.j,\n",
       "        -2.70721945e-02+0.j, -6.06275745e-02+0.j, -3.59414785e-02+0.j,\n",
       "        -9.87778517e-02+0.j, -5.65639270e-02+0.j,  6.86185179e-02+0.j,\n",
       "         7.29756049e-02+0.j],\n",
       "       [ 1.75090934e-01+0.j, -2.17268286e-01+0.j,  2.02122533e-02+0.j,\n",
       "         1.94912906e-01+0.j,  1.15208333e-02+0.j,  1.68019081e-02+0.j,\n",
       "         8.99321235e-02+0.j,  3.80337936e-02+0.j,  9.75716614e-02+0.j,\n",
       "        -5.39155136e-02+0.j, -6.53514227e-02+0.j, -1.03677926e-01+0.j,\n",
       "        -1.26913345e-01+0.j, -4.47320085e-02+0.j,  2.86189202e-02+0.j,\n",
       "         4.27644163e-02+0.j],\n",
       "       [ 2.10512297e-01+0.j,  5.54290877e-02+0.j, -1.95379310e-01+0.j,\n",
       "         2.45353406e-01+0.j,  9.14403264e-02+0.j,  1.27672844e-02+0.j,\n",
       "        -2.09352824e-02+0.j,  2.07583441e-02+0.j,  7.76861753e-02+0.j,\n",
       "        -8.81575175e-02+0.j,  1.31052218e-01+0.j, -7.37229756e-02+0.j,\n",
       "        -9.17905836e-02+0.j,  2.35202374e-02+0.j,  1.13661743e-01+0.j,\n",
       "         1.35212096e-01+0.j],\n",
       "       [ 1.16823134e-01+0.j,  2.08023518e-01+0.j, -2.42120607e-01+0.j,\n",
       "         9.87898423e-02+0.j,  8.11957608e-02+0.j,  1.90544053e-02+0.j,\n",
       "        -1.00014912e-01+0.j, -1.21660433e-02+0.j,  4.36051505e-02+0.j,\n",
       "        -7.28855503e-02+0.j,  2.34616855e-01+0.j, -6.24725227e-02+0.j,\n",
       "        -4.88990851e-02+0.j, -3.91454907e-02+0.j,  1.01532347e-01+0.j,\n",
       "         7.54008905e-02+0.j],\n",
       "       [-1.21758001e-01+0.j,  2.40953498e-01+0.j, -7.02620203e-02+0.j,\n",
       "        -5.26559272e-02+0.j, -9.69976956e-03+0.j, -2.38352112e-02+0.j,\n",
       "         2.11587972e-01+0.j, -3.80115265e-02+0.j,  2.89216391e-02+0.j,\n",
       "         1.04893726e-01+0.j,  2.49102447e-01+0.j, -2.97863656e-01+0.j,\n",
       "        -2.55837283e-01+0.j, -9.49426768e-02+0.j,  2.34617057e-02+0.j,\n",
       "         5.19287283e-02+0.j],\n",
       "       [-1.65392760e-01+0.j,  2.18962996e-01+0.j, -2.64505973e-02+0.j,\n",
       "        -1.08488358e-01+0.j, -2.06960357e-02+0.j, -2.51744427e-02+0.j,\n",
       "         2.38962527e-01+0.j, -9.72739136e-03+0.j, -4.70982359e-03+0.j,\n",
       "         1.15849894e-01+0.j,  1.50931712e-01+0.j, -2.58566345e-01+0.j,\n",
       "        -2.38156323e-01+0.j, -2.39299402e-02+0.j,  5.74018816e-03+0.j,\n",
       "         5.24405958e-02+0.j],\n",
       "       [-4.93509442e-02+0.j,  2.91761434e-01+0.j, -1.63724067e-01+0.j,\n",
       "         3.55677031e-02+0.j,  3.83886035e-02+0.j, -7.80131912e-03+0.j,\n",
       "         8.41772928e-02+0.j,  1.19134772e-02+0.j,  4.30247238e-02+0.j,\n",
       "         2.05990931e-02+0.j, -9.89628705e-02+0.j,  1.70182229e-02+0.j,\n",
       "        -2.96365526e-02+0.j,  3.58397447e-02+0.j,  2.71569431e-02+0.j,\n",
       "         4.16181919e-02+0.j],\n",
       "       [-4.93507238e-02+0.j,  2.91761491e-01+0.j, -1.63724056e-01+0.j,\n",
       "         3.55676529e-02+0.j,  3.83884424e-02+0.j, -7.80191617e-03+0.j,\n",
       "         8.41774600e-02+0.j,  1.19134973e-02+0.j,  4.30237932e-02+0.j,\n",
       "         2.05981106e-02+0.j, -9.89633610e-02+0.j,  1.70178311e-02+0.j,\n",
       "        -2.96358154e-02+0.j,  3.58371590e-02+0.j,  2.71543599e-02+0.j,\n",
       "         4.16159760e-02+0.j],\n",
       "       [ 3.56367719e-02+0.j,  2.25761067e-01+0.j, -2.48412569e-01+0.j,\n",
       "        -1.23058377e-01+0.j,  7.57657461e-02+0.j,  1.58744527e-02+0.j,\n",
       "        -2.08106496e-01+0.j, -3.75203024e-02+0.j, -8.87641221e-02+0.j,\n",
       "        -8.00386715e-02+0.j,  2.60076357e-01+0.j, -3.53851476e-02+0.j,\n",
       "         5.20119415e-02+0.j,  8.13294394e-02+0.j, -5.96390329e-02+0.j,\n",
       "        -5.36710600e-02+0.j],\n",
       "       [-1.57399096e-01+0.j,  1.44945768e-01+0.j,  1.07476132e-01+0.j,\n",
       "         1.31114499e-01+0.j, -6.27363364e-02+0.j, -5.37596787e-02+0.j,\n",
       "         4.06427685e-01+0.j,  9.14319542e-02+0.j,  2.14177934e-02+0.j,\n",
       "         1.01305299e-01+0.j, -2.94810392e-01+0.j,  6.23752308e-03+0.j,\n",
       "        -1.41389408e-01+0.j,  7.73147435e-02+0.j,  1.73369567e-01+0.j,\n",
       "         1.72104886e-01+0.j],\n",
       "       [ 1.74163075e-01+0.j, -4.12151420e-02+0.j, -1.39205578e-01+0.j,\n",
       "         1.61975907e-01+0.j,  1.02355211e-01+0.j, -1.04535135e-02+0.j,\n",
       "         1.87454945e-01+0.j,  8.25747296e-02+0.j, -3.00089857e-01+0.j,\n",
       "         9.91795233e-03+0.j, -1.67223262e-01+0.j, -1.07531968e-02+0.j,\n",
       "        -8.02167896e-02+0.j,  7.95272428e-01+0.j, -1.51400086e-01+0.j,\n",
       "        -7.67338288e-02+0.j],\n",
       "       [-1.07534576e-01+0.j,  1.26246528e-02+0.j,  1.13164896e-01+0.j,\n",
       "        -8.90089196e-02+0.j, -1.21314175e-01+0.j,  1.45964062e-02+0.j,\n",
       "        -1.13977591e-01+0.j, -8.23523936e-02+0.j,  8.53251311e-01+0.j,\n",
       "        -4.63402291e-02+0.j,  8.23843267e-02+0.j,  1.79902812e-02+0.j,\n",
       "        -5.51894054e-02+0.j,  4.33424712e-01+0.j, -4.12796603e-02+0.j,\n",
       "         3.05695986e-03+0.j],\n",
       "       [ 2.94443531e-02+0.j,  2.48373886e-01+0.j, -2.06256189e-01+0.j,\n",
       "         5.11435642e-02+0.j,  6.48226334e-02+0.j,  7.31571484e-02+0.j,\n",
       "        -3.05513327e-02+0.j,  2.26017186e-02+0.j,  1.47165550e-01+0.j,\n",
       "        -5.31643711e-02+0.j, -3.50357042e-01+0.j,  1.89672711e-01+0.j,\n",
       "         1.60991217e-01+0.j, -1.44998895e-01+0.j, -6.07210103e-02+0.j,\n",
       "        -8.57289711e-02+0.j],\n",
       "       [ 5.02217262e-03+0.j,  2.43743090e-01+0.j, -1.85841609e-01+0.j,\n",
       "         1.19225019e-01+0.j,  6.74192896e-02+0.j,  3.39038259e-02+0.j,\n",
       "        -2.32913569e-02+0.j,  2.52320927e-02+0.j,  1.58431610e-01+0.j,\n",
       "        -2.72840024e-02+0.j, -3.94149047e-01+0.j,  2.15527409e-01+0.j,\n",
       "         1.27595596e-01+0.j, -1.67714244e-01+0.j, -3.47849624e-02+0.j,\n",
       "        -9.00930345e-02+0.j],\n",
       "       [ 1.54542520e-01+0.j, -1.04156368e-01+0.j, -1.29415550e-01+0.j,\n",
       "        -2.54538429e-01+0.j,  1.21764618e-02+0.j, -1.21482920e-02+0.j,\n",
       "         2.21126507e-01+0.j,  1.58266503e-02+0.j,  8.90015761e-02+0.j,\n",
       "        -5.05455701e-03+0.j, -2.18319852e-01+0.j, -7.00729630e-02+0.j,\n",
       "        -1.96779546e-01+0.j, -9.77467281e-02+0.j,  3.83373284e-01+0.j,\n",
       "         2.65487608e-01+0.j],\n",
       "       [ 1.81776921e-01+0.j, -1.15079619e-01+0.j, -1.70362157e-01+0.j,\n",
       "        -3.29822458e-01+0.j,  3.28088431e-02+0.j,  1.34120216e-02+0.j,\n",
       "         1.13826189e-01+0.j,  4.34644945e-03+0.j,  4.15204808e-02+0.j,\n",
       "        -3.68843259e-03+0.j, -9.10933721e-03+0.j,  4.44298649e-02+0.j,\n",
       "         2.03150460e-02+0.j, -1.45162939e-03+0.j, -4.52007841e-02+0.j,\n",
       "        -2.37794803e-02+0.j],\n",
       "       [-1.81776921e-01+0.j,  1.15079619e-01+0.j,  1.70362157e-01+0.j,\n",
       "         3.29822458e-01+0.j, -3.28088431e-02+0.j, -1.34120216e-02+0.j,\n",
       "        -1.13826189e-01+0.j, -4.34644945e-03+0.j, -4.15204808e-02+0.j,\n",
       "         3.68843259e-03+0.j,  9.10933721e-03+0.j, -4.44298649e-02+0.j,\n",
       "        -2.03150460e-02+0.j,  1.45162939e-03+0.j,  4.52007841e-02+0.j,\n",
       "         2.37794803e-02+0.j],\n",
       "       [ 1.81776921e-01+0.j, -1.15079619e-01+0.j, -1.70362157e-01+0.j,\n",
       "        -3.29822458e-01+0.j,  3.28088431e-02+0.j,  1.34120216e-02+0.j,\n",
       "         1.13826189e-01+0.j,  4.34644945e-03+0.j,  4.15204808e-02+0.j,\n",
       "        -3.68843259e-03+0.j, -9.10933721e-03+0.j,  4.44298649e-02+0.j,\n",
       "         2.03150460e-02+0.j, -1.45162939e-03+0.j, -4.52007841e-02+0.j,\n",
       "        -2.37794803e-02+0.j],\n",
       "       [-1.81776921e-01+0.j,  1.15079619e-01+0.j,  1.70362157e-01+0.j,\n",
       "         3.29822458e-01+0.j, -3.28088431e-02+0.j, -1.34120216e-02+0.j,\n",
       "        -1.13826189e-01+0.j, -4.34644945e-03+0.j, -4.15204808e-02+0.j,\n",
       "         3.68843259e-03+0.j,  9.10933721e-03+0.j, -4.44298649e-02+0.j,\n",
       "        -2.03150460e-02+0.j,  1.45162939e-03+0.j,  4.52007841e-02+0.j,\n",
       "         2.37794803e-02+0.j],\n",
       "       [-1.65306341e-02+0.j,  1.06995940e-02+0.j,  3.12364675e-02+0.j,\n",
       "         8.83861397e-02+0.j, -2.93400790e-02+0.j, -7.80353248e-03+0.j,\n",
       "         3.66801803e-01+0.j, -8.12907149e-01+0.j, -5.70136683e-02+0.j,\n",
       "        -3.79847255e-01+0.j,  8.32254859e-02+0.j,  1.63320498e-01+0.j,\n",
       "         1.08411090e-01+0.j,  5.07046257e-04+0.j,  9.39666653e-04+0.j,\n",
       "        -1.19627109e-02+0.j],\n",
       "       [-7.61795197e-02+0.j,  2.58887862e-02+0.j,  6.30842747e-02+0.j,\n",
       "         6.80819639e-02+0.j,  1.85252627e-02+0.j, -1.22099110e-02+0.j,\n",
       "         4.87571048e-01+0.j,  5.41320776e-01+0.j,  9.10523044e-02+0.j,\n",
       "        -4.39170352e-01+0.j,  3.35059065e-01+0.j,  1.88165249e-01+0.j,\n",
       "         2.41414070e-01+0.j, -6.94913440e-02+0.j, -7.41521549e-02+0.j,\n",
       "        -1.14407978e-01+0.j],\n",
       "       [ 2.02886305e-01+0.j,  1.56421637e-01+0.j,  1.75640860e-01+0.j,\n",
       "        -2.33957476e-02+0.j,  1.42746122e-02+0.j,  6.62589820e-03+0.j,\n",
       "        -2.91979032e-05+0.j,  6.47977946e-04+0.j,  2.21798680e-02+0.j,\n",
       "        -2.09963714e-02+0.j, -4.36867659e-02+0.j, -6.79137123e-02+0.j,\n",
       "         4.55094354e-02+0.j, -3.43030986e-02+0.j,  3.46663948e-03+0.j,\n",
       "         4.47367292e-02+0.j],\n",
       "       [ 1.55063102e-01+0.j,  7.61707463e-02+0.j, -1.95768955e-02+0.j,\n",
       "        -3.64847553e-03+0.j, -3.68125165e-01+0.j, -2.15148086e-01+0.j,\n",
       "         1.15362433e-02+0.j,  1.11704776e-02+0.j,  2.52885863e-02+0.j,\n",
       "        -2.71224704e-01+0.j, -2.39061189e-01+0.j, -4.03317292e-01+0.j,\n",
       "        -2.35976810e-01+0.j, -1.52371433e-01+0.j, -4.95057821e-01+0.j,\n",
       "        -2.90414983e-01+0.j],\n",
       "       [-3.35975289e-02+0.j, -2.37291439e-02+0.j, -1.07877781e-01+0.j,\n",
       "         3.84999979e-02+0.j, -3.80547387e-01+0.j,  5.22966640e-01+0.j,\n",
       "         1.00650097e-02+0.j,  3.21574453e-02+0.j, -7.47485985e-02+0.j,\n",
       "         5.20865475e-02+0.j,  8.75360032e-02+0.j,  3.39594263e-01+0.j,\n",
       "        -2.62799764e-01+0.j, -4.96952238e-02+0.j, -4.08165775e-01+0.j,\n",
       "         4.12650093e-01+0.j],\n",
       "       [-1.54965091e-01+0.j, -8.41688601e-02+0.j,  2.16196420e-02+0.j,\n",
       "        -2.06325425e-02+0.j,  4.39374639e-01+0.j,  2.90793942e-01+0.j,\n",
       "        -2.62665264e-02+0.j, -1.49610790e-02+0.j,  3.90581236e-02+0.j,\n",
       "        -1.83635333e-01+0.j, -8.66441040e-02+0.j, -1.63984109e-02+0.j,\n",
       "        -3.96289167e-01+0.j, -7.34936541e-02+0.j, -7.50407493e-02+0.j,\n",
       "        -2.67437867e-01+0.j],\n",
       "       [-1.90337052e-01+0.j, -8.95166192e-02+0.j,  4.49166491e-02+0.j,\n",
       "        -2.64655887e-02+0.j,  4.07487217e-01+0.j,  2.61150562e-01+0.j,\n",
       "        -1.20616924e-02+0.j,  1.57315396e-03+0.j,  1.07497514e-02+0.j,\n",
       "        -1.07355089e-01+0.j, -5.13214111e-02+0.j,  2.05697632e-02+0.j,\n",
       "        -2.54742284e-01+0.j, -3.03542320e-02+0.j, -5.18997246e-02+0.j,\n",
       "        -1.38565693e-01+0.j],\n",
       "       [ 1.51895727e-02+0.j,  8.81410642e-03+0.j,  7.23607895e-02+0.j,\n",
       "        -7.67311820e-03+0.j,  3.22190848e-01+0.j, -6.05508125e-01+0.j,\n",
       "        -4.30788585e-02+0.j, -5.87936193e-03+0.j,  3.57302194e-02+0.j,\n",
       "         4.10608566e-02+0.j,  5.79286472e-02+0.j,  3.67333051e-01+0.j,\n",
       "        -2.81486605e-01+0.j, -7.58636533e-02+0.j, -3.23376347e-01+0.j,\n",
       "         3.27279018e-01+0.j],\n",
       "       [ 2.13192931e-01+0.j,  1.58465931e-01+0.j,  1.92833720e-01+0.j,\n",
       "        -3.74065121e-02+0.j, -4.60158255e-02+0.j,  1.30888499e-01+0.j,\n",
       "         5.97925386e-04+0.j,  4.59191224e-03+0.j, -1.68167169e-02+0.j,\n",
       "         2.68896735e-02+0.j,  3.91031651e-02+0.j,  1.23942998e-01+0.j,\n",
       "        -1.09441055e-01+0.j,  8.95699109e-03+0.j,  9.60028458e-02+0.j,\n",
       "        -1.02807474e-01+0.j],\n",
       "       [-1.97976846e-01+0.j, -1.63843825e-01+0.j, -1.88367125e-01+0.j,\n",
       "         2.97356216e-02+0.j,  1.01997269e-02+0.j, -1.91981616e-01+0.j,\n",
       "        -7.69122497e-03+0.j, -6.10181867e-03+0.j,  2.33951560e-03+0.j,\n",
       "        -3.71978868e-04+0.j, -5.97812379e-04+0.j, -1.97349991e-02+0.j,\n",
       "         2.26632934e-02+0.j, -7.01177988e-03+0.j, -6.74461807e-02+0.j,\n",
       "        -2.68583720e-02+0.j],\n",
       "       [ 2.09820215e-01+0.j,  1.54790395e-01+0.j,  2.10586804e-01+0.j,\n",
       "        -4.98190977e-02+0.j,  1.02933965e-02+0.j, -6.88517089e-02+0.j,\n",
       "        -4.14751696e-03+0.j,  4.59746927e-03+0.j, -1.45001058e-02+0.j,\n",
       "         2.27856119e-02+0.j,  1.40802473e-02+0.j,  8.58459621e-02+0.j,\n",
       "        -2.39042238e-02+0.j, -6.83759068e-03+0.j, -7.85745544e-02+0.j,\n",
       "         2.83599072e-02+0.j],\n",
       "       [ 2.02508603e-01+0.j,  1.37614018e-01+0.j,  1.60063953e-01+0.j,\n",
       "        -2.48556027e-02+0.j, -1.11975883e-01+0.j, -2.40545855e-02+0.j,\n",
       "        -1.48909430e-02+0.j,  8.09749154e-03+0.j, -4.51802021e-02+0.j,\n",
       "         7.22499708e-02+0.j,  1.13394689e-01+0.j,  2.95024361e-01+0.j,\n",
       "        -2.89279102e-01+0.j,  9.01716726e-03+0.j,  2.24319747e-01+0.j,\n",
       "        -3.69729141e-01+0.j],\n",
       "       [ 0.00000000e+00+0.j,  0.00000000e+00+0.j,  0.00000000e+00+0.j,\n",
       "         0.00000000e+00+0.j,  0.00000000e+00+0.j,  0.00000000e+00+0.j,\n",
       "         0.00000000e+00+0.j,  0.00000000e+00+0.j,  0.00000000e+00+0.j,\n",
       "         0.00000000e+00+0.j,  0.00000000e+00+0.j,  0.00000000e+00+0.j,\n",
       "         0.00000000e+00+0.j,  0.00000000e+00+0.j,  0.00000000e+00+0.j,\n",
       "         0.00000000e+00+0.j],\n",
       "       [ 2.12680814e-01+0.j,  1.48563828e-01+0.j,  2.06394912e-01+0.j,\n",
       "        -5.27662947e-02+0.j, -2.15921848e-02+0.j, -6.17312002e-02+0.j,\n",
       "        -8.59221576e-03+0.j,  3.05396432e-03+0.j, -3.15865920e-02+0.j,\n",
       "         3.36378721e-02+0.j,  5.17302054e-02+0.j,  1.52949985e-01+0.j,\n",
       "        -1.23559070e-01+0.j,  1.35962186e-03+0.j,  1.85040371e-02+0.j,\n",
       "        -1.37082465e-01+0.j],\n",
       "       [ 2.14433985e-01+0.j,  1.65076171e-01+0.j,  1.98373252e-01+0.j,\n",
       "        -3.87756392e-02+0.j, -3.44514438e-02+0.j,  1.41231942e-01+0.j,\n",
       "         2.94861870e-03+0.j,  3.38973313e-03+0.j, -1.13475653e-02+0.j,\n",
       "         3.05021643e-03+0.j,  6.62212031e-03+0.j,  2.16503336e-02+0.j,\n",
       "        -2.73617990e-02+0.j,  7.03071634e-03+0.j,  5.24169756e-02+0.j,\n",
       "        -1.22920844e-02+0.j],\n",
       "       [ 1.35325913e-01+0.j,  1.31030596e-01+0.j,  2.52911617e-01+0.j,\n",
       "        -8.18082265e-02+0.j,  2.20216276e-01+0.j,  2.36746035e-01+0.j,\n",
       "         1.83725638e-02+0.j, -7.97999502e-03+0.j,  7.60476270e-03+0.j,\n",
       "        -6.01193617e-02+0.j, -7.25402559e-02+0.j, -2.66826096e-01+0.j,\n",
       "         2.34646630e-01+0.j,  1.86217893e-02+0.j, -1.68315111e-01+0.j,\n",
       "         2.63909353e-01+0.j],\n",
       "       [ 1.41745472e-01+0.j,  1.28136636e-01+0.j,  2.72257869e-01+0.j,\n",
       "        -8.58596737e-02+0.j,  2.89428081e-01+0.j,  3.00492270e-02+0.j,\n",
       "         4.47929862e-03+0.j, -9.93054669e-03+0.j,  3.56819810e-03+0.j,\n",
       "        -4.24265950e-02+0.j, -3.74578528e-02+0.j, -1.58360864e-01+0.j,\n",
       "         1.48050128e-01+0.j,  1.19673141e-02+0.j, -1.83820158e-01+0.j,\n",
       "         2.15309179e-01+0.j]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_reduce=eig_vecs[:,:16]#last vector dropped due to insignificance\n",
    "p_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5839, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca=np.dot(x,p_reduce)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-510.5036080362648+0j)</td>\n",
       "      <td>(623.9675365093136+0j)</td>\n",
       "      <td>(-47.86412652548065+0j)</td>\n",
       "      <td>(-388.30648518177827+0j)</td>\n",
       "      <td>(-38.265357915580736+0j)</td>\n",
       "      <td>(17.67016847625516+0j)</td>\n",
       "      <td>(51.85359568657729+0j)</td>\n",
       "      <td>(17.11705158264278+0j)</td>\n",
       "      <td>(-20.669831678800158+0j)</td>\n",
       "      <td>(107.154101653477+0j)</td>\n",
       "      <td>(-596.2479025985276+0j)</td>\n",
       "      <td>(347.0898070070306+0j)</td>\n",
       "      <td>(239.61130432152746+0j)</td>\n",
       "      <td>(28.094092796460412+0j)</td>\n",
       "      <td>(-116.42717433149139+0j)</td>\n",
       "      <td>(-190.16165284724477+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-500.8363051542913+0j)</td>\n",
       "      <td>(753.9336905978505+0j)</td>\n",
       "      <td>(-153.68732479664467+0j)</td>\n",
       "      <td>(-353.5415686634778+0j)</td>\n",
       "      <td>(-3.3680338771522136+0j)</td>\n",
       "      <td>(44.99816166675219+0j)</td>\n",
       "      <td>(42.660156483888784+0j)</td>\n",
       "      <td>(28.500004558302+0j)</td>\n",
       "      <td>(53.785236683565394+0j)</td>\n",
       "      <td>(87.79300591451819+0j)</td>\n",
       "      <td>(-773.7709114023339+0j)</td>\n",
       "      <td>(442.89837236026+0j)</td>\n",
       "      <td>(308.61497160532406+0j)</td>\n",
       "      <td>(-45.97745886324871+0j)</td>\n",
       "      <td>(-140.87594063931587+0j)</td>\n",
       "      <td>(-231.87350576987114+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-505.4172767544455+0j)</td>\n",
       "      <td>(688.6636168130588+0j)</td>\n",
       "      <td>(-98.72591407631188+0j)</td>\n",
       "      <td>(-361.3645366958265+0j)</td>\n",
       "      <td>(-21.006656374604166+0j)</td>\n",
       "      <td>(29.838129808333342+0j)</td>\n",
       "      <td>(45.017688550588936+0j)</td>\n",
       "      <td>(22.37305856337711+0j)</td>\n",
       "      <td>(16.082747424464273+0j)</td>\n",
       "      <td>(97.11475872102869+0j)</td>\n",
       "      <td>(-678.6992469815797+0j)</td>\n",
       "      <td>(391.03643261783435+0j)</td>\n",
       "      <td>(270.1971621870191+0j)</td>\n",
       "      <td>(-6.74456257959003+0j)</td>\n",
       "      <td>(-126.02397518333291+0j)</td>\n",
       "      <td>(-208.05794998936145+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-481.60787511284815+0j)</td>\n",
       "      <td>(556.2564519684543+0j)</td>\n",
       "      <td>(-21.07379825627842+0j)</td>\n",
       "      <td>(-375.73722261446215+0j)</td>\n",
       "      <td>(-43.92694233325182+0j)</td>\n",
       "      <td>(9.8754782497594+0j)</td>\n",
       "      <td>(51.364611951808+0j)</td>\n",
       "      <td>(13.206016223721186+0j)</td>\n",
       "      <td>(-38.78034619703974+0j)</td>\n",
       "      <td>(105.60599671214781+0j)</td>\n",
       "      <td>(-513.6672578129636+0j)</td>\n",
       "      <td>(301.94397690484936+0j)</td>\n",
       "      <td>(207.53698636793638+0j)</td>\n",
       "      <td>(49.95466758146051+0j)</td>\n",
       "      <td>(-102.95615753890014+0j)</td>\n",
       "      <td>(-167.1282661112384+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-484.21828132305984+0j)</td>\n",
       "      <td>(534.7269119660041+0j)</td>\n",
       "      <td>(-2.519324098199143+0j)</td>\n",
       "      <td>(-381.8184379679582+0j)</td>\n",
       "      <td>(-50.23708612134294+0j)</td>\n",
       "      <td>(4.631162177584004+0j)</td>\n",
       "      <td>(53.491573140931514+0j)</td>\n",
       "      <td>(11.206793227882201+0j)</td>\n",
       "      <td>(-52.39071117553274+0j)</td>\n",
       "      <td>(108.84090566954973+0j)</td>\n",
       "      <td>(-480.6153911925461+0j)</td>\n",
       "      <td>(283.58658619179477+0j)</td>\n",
       "      <td>(193.83222517737886+0j)</td>\n",
       "      <td>(64.37050410105127+0j)</td>\n",
       "      <td>(-97.91099369041608+0j)</td>\n",
       "      <td>(-158.6349744910585+0j)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                       1                         2   \\\n",
       "0   (-510.5036080362648+0j)  (623.9675365093136+0j)   (-47.86412652548065+0j)   \n",
       "1   (-500.8363051542913+0j)  (753.9336905978505+0j)  (-153.68732479664467+0j)   \n",
       "2   (-505.4172767544455+0j)  (688.6636168130588+0j)   (-98.72591407631188+0j)   \n",
       "3  (-481.60787511284815+0j)  (556.2564519684543+0j)   (-21.07379825627842+0j)   \n",
       "4  (-484.21828132305984+0j)  (534.7269119660041+0j)   (-2.519324098199143+0j)   \n",
       "\n",
       "                         3                         4   \\\n",
       "0  (-388.30648518177827+0j)  (-38.265357915580736+0j)   \n",
       "1   (-353.5415686634778+0j)  (-3.3680338771522136+0j)   \n",
       "2   (-361.3645366958265+0j)  (-21.006656374604166+0j)   \n",
       "3  (-375.73722261446215+0j)   (-43.92694233325182+0j)   \n",
       "4   (-381.8184379679582+0j)   (-50.23708612134294+0j)   \n",
       "\n",
       "                        5                        6                        7   \\\n",
       "0   (17.67016847625516+0j)   (51.85359568657729+0j)   (17.11705158264278+0j)   \n",
       "1   (44.99816166675219+0j)  (42.660156483888784+0j)     (28.500004558302+0j)   \n",
       "2  (29.838129808333342+0j)  (45.017688550588936+0j)   (22.37305856337711+0j)   \n",
       "3     (9.8754782497594+0j)     (51.364611951808+0j)  (13.206016223721186+0j)   \n",
       "4   (4.631162177584004+0j)  (53.491573140931514+0j)  (11.206793227882201+0j)   \n",
       "\n",
       "                         8                        9                        10  \\\n",
       "0  (-20.669831678800158+0j)    (107.154101653477+0j)  (-596.2479025985276+0j)   \n",
       "1   (53.785236683565394+0j)   (87.79300591451819+0j)  (-773.7709114023339+0j)   \n",
       "2   (16.082747424464273+0j)   (97.11475872102869+0j)  (-678.6992469815797+0j)   \n",
       "3   (-38.78034619703974+0j)  (105.60599671214781+0j)  (-513.6672578129636+0j)   \n",
       "4   (-52.39071117553274+0j)  (108.84090566954973+0j)  (-480.6153911925461+0j)   \n",
       "\n",
       "                        11                       12                       13  \\\n",
       "0   (347.0898070070306+0j)  (239.61130432152746+0j)  (28.094092796460412+0j)   \n",
       "1     (442.89837236026+0j)  (308.61497160532406+0j)  (-45.97745886324871+0j)   \n",
       "2  (391.03643261783435+0j)   (270.1971621870191+0j)   (-6.74456257959003+0j)   \n",
       "3  (301.94397690484936+0j)  (207.53698636793638+0j)   (49.95466758146051+0j)   \n",
       "4  (283.58658619179477+0j)  (193.83222517737886+0j)   (64.37050410105127+0j)   \n",
       "\n",
       "                         14                        15  \n",
       "0  (-116.42717433149139+0j)  (-190.16165284724477+0j)  \n",
       "1  (-140.87594063931587+0j)  (-231.87350576987114+0j)  \n",
       "2  (-126.02397518333291+0j)  (-208.05794998936145+0j)  \n",
       "3  (-102.95615753890014+0j)   (-167.1282661112384+0j)  \n",
       "4   (-97.91099369041608+0j)   (-158.6349744910585+0j)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_PCA=pd.DataFrame(X_pca)\n",
    "X_PCA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model building \n",
    "    using k fold crossvalidation and we can check which model performs best as base model and then we can do hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()\n",
    "KNN=KNeighborsClassifier(n_neighbors=9,weights='distance')\n",
    "DT=DecisionTreeClassifier()\n",
    "RF=RandomForestClassifier(n_estimators=10)\n",
    "Bagged=BaggingClassifier(n_estimators=50)\n",
    "AdaBoost=AdaBoostClassifier(n_estimators=50)\n",
    "AB_RF=AdaBoostClassifier(base_estimator=RF,n_estimators=100)\n",
    "GBoost=GradientBoostingClassifier(n_estimators=920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('MVLR', LR))\n",
    "models.append(('KNNRegressor',KNN))\n",
    "models.append(('DT_Regressor',DT))\n",
    "models.append(('RandomForest',RF))\n",
    "models.append(('BaggedRegressor',Bagged))\n",
    "models.append(('AdaBoostRegressor',AdaBoost))\n",
    "models.append(('AdaBoostRF',AB_RF))\n",
    "models.append(('GradientBoostRegressor',GBoost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVLR: 1.734381 (0.052453)\n",
      "KNNRegressor: 1.623755 (0.063839)\n",
      "DT_Regressor: 1.883047 (0.047509)\n",
      "RandomForest: 1.728133 (0.052940)\n",
      "BaggedRegressor: 1.645285 (0.051850)\n",
      "AdaBoostRegressor: 1.892981 (0.027549)\n",
      "AdaBoostRF: 1.583065 (0.031434)\n",
      "GradientBoostRegressor: 1.689091 (0.050463)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(shuffle=True,n_splits=7,random_state=0)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train_2, y_train,cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(np.sqrt(np.abs(cv_results)))\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n",
    "   # boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost classifier with random forest as base estimator gives the less errors lets see the accuracy after appyling model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train_2,y_train)\n",
    "y_pred=logreg.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "## Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4178082191780822"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23,  47, 102,   0,  13,  14],\n",
       "       [ 15,  84, 117,   0,  12,   7],\n",
       "       [  7,  27, 257,   0,   6,  21],\n",
       "       [  2,   1,  10,   0,  29,   7],\n",
       "       [ 14,  22,  89,   0,  67,  29],\n",
       "       [  7,  19,  44,   0,  19,  57]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 23  47 102   0  13  14]\n",
      " [ 15  84 117   0  12   7]\n",
      " [  7  27 257   0   6  21]\n",
      " [  2   1  10   0  29   7]\n",
      " [ 14  22  89   0  67  29]\n",
      " [  7  19  44   0  19  57]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix=confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4,5])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot \n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1,2,3,4,5],\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245781</td>\n",
       "      <td>0.104021</td>\n",
       "      <td>0.376136</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>0.090780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.123301</td>\n",
       "      <td>0.218767</td>\n",
       "      <td>0.446361</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.148670</td>\n",
       "      <td>0.029820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324259</td>\n",
       "      <td>0.273285</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.164482</td>\n",
       "      <td>0.034830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180424</td>\n",
       "      <td>0.290238</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.070781</td>\n",
       "      <td>0.173401</td>\n",
       "      <td>0.064339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221256</td>\n",
       "      <td>0.104548</td>\n",
       "      <td>0.349714</td>\n",
       "      <td>0.024625</td>\n",
       "      <td>0.147998</td>\n",
       "      <td>0.151858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  0.245781  0.104021  0.376136  0.019402  0.163880  0.090780\n",
       "1  0.123301  0.218767  0.446361  0.033080  0.148670  0.029820\n",
       "2  0.324259  0.273285  0.187959  0.015185  0.164482  0.034830\n",
       "3  0.180424  0.290238  0.220816  0.070781  0.173401  0.064339\n",
       "4  0.221256  0.104548  0.349714  0.024625  0.147998  0.151858"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob=logreg.predict_proba(X_test_2)[:,:]\n",
    "y_pred_prob_df=pd.DataFrame(data=y_pred_prob, columns=[0,1,2,3,4,5])\n",
    "y_pred_prob_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "giniDecisionTree = DecisionTreeClassifier(criterion='gini',random_state = 100,max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "giniDecisionTree.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.40847784200385356\n",
      "Test accuracy: 0.3767123287671233\n"
     ]
    }
   ],
   "source": [
    "# predicting X_test\n",
    "y_pred =giniDecisionTree.predict(X_test_2)\n",
    "\n",
    "# checking for model overfit\n",
    "print(\"Training accuracy:\", accuracy_score(y_train,giniDecisionTree.predict(X_train_2)))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Rondom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "fit_rf = RandomForestClassifier(random_state=42)\n",
    "fit_rf.fit(X_train_2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9892956540355384\n",
      "Test accuracy: 0.511986301369863\n"
     ]
    }
   ],
   "source": [
    "# predicting X_test\n",
    "y_pred = fit_rf.predict(X_test_2)\n",
    "\n",
    "# checking for model overfit\n",
    "print(\"Training accuracy:\", accuracy_score(y_train,fit_rf.predict(X_train_2)))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.39      0.43       199\n",
      "           1       0.50      0.49      0.49       235\n",
      "           2       0.58      0.83      0.68       318\n",
      "           3       0.64      0.18      0.29        49\n",
      "           4       0.67      0.52      0.58       221\n",
      "           5       0.55      0.50      0.52       146\n",
      "\n",
      "    accuracy                           0.56      1168\n",
      "   macro avg       0.57      0.48      0.50      1168\n",
      "weighted avg       0.56      0.56      0.55      1168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(base_estimator=fit_rf).fit(X_train_2,y_train)\n",
    "y_pred=ada.predict(X_test_2)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9997859130807107\n",
      "Test accuracy: 0.5582191780821918\n"
     ]
    }
   ],
   "source": [
    "# predicting X_test\n",
    "y_pred = ada.predict(X_test_2)\n",
    "\n",
    "# checking for model overfit\n",
    "print(\"Training accuracy:\", accuracy_score(y_train,ada.predict(X_train_2)))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance data treatment--SMOTE (over sampling)\n",
    "    - SMOTE stands for Synthetic Minority Over-sampling Technique.\n",
    "    - Unlike Random UnderSampling, SMOTE creates new synthetic points in order to have an equal balance of the classes.\n",
    "    - This is another alternative for solving the \"class imbalance problems\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLYING PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = PCA(n_components=16).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X1, y1 = sm.fit_sample(X_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2,X_test2,y_train2,y_test2=train_test_split(X1,y1,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.09      0.12       440\n",
      "           1       0.34      0.45      0.39       411\n",
      "           2       0.37      0.45      0.41       431\n",
      "           3       0.55      0.62      0.58       422\n",
      "           4       0.39      0.24      0.30       435\n",
      "           5       0.38      0.54      0.45       402\n",
      "\n",
      "    accuracy                           0.39      2541\n",
      "   macro avg       0.38      0.40      0.38      2541\n",
      "weighted avg       0.38      0.39      0.37      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_up=LogisticRegression().fit(X_train2,y_train2)\n",
    "y_pred_lr_up=lr_up.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test2,y_pred_lr_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39354584809130266"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2,y_pred_lr_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see after over sampling the model accuracy gone down using logistic where as before over sampling it got 42% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54       440\n",
      "           1       0.50      0.55      0.52       411\n",
      "           2       0.50      0.49      0.49       431\n",
      "           3       0.80      0.80      0.80       422\n",
      "           4       0.61      0.56      0.58       435\n",
      "           5       0.64      0.66      0.65       402\n",
      "\n",
      "    accuracy                           0.60      2541\n",
      "   macro avg       0.60      0.60      0.60      2541\n",
      "weighted avg       0.60      0.60      0.60      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_up=DecisionTreeClassifier().fit(X_train2,y_train2)\n",
    "y_pred_dt_up=dt_up.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test2,y_pred_dt_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5958284140102322"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2,y_pred_dt_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### over sampling has increased the accuracy of the decision tree model to 59% from 37%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.61       440\n",
      "           1       0.56      0.58      0.57       411\n",
      "           2       0.61      0.57      0.59       431\n",
      "           3       0.86      0.91      0.88       422\n",
      "           4       0.74      0.66      0.70       435\n",
      "           5       0.76      0.76      0.76       402\n",
      "\n",
      "    accuracy                           0.69      2541\n",
      "   macro avg       0.69      0.69      0.69      2541\n",
      "weighted avg       0.69      0.69      0.69      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_up=RandomForestClassifier().fit(X_train2,y_train2)\n",
    "y_pred_rf_up=rf_up.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test2,y_pred_rf_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6855568673750492"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2,y_pred_rf_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest has incresed the acuuracy and also classifying the classes more accurately than decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.51      0.53       440\n",
      "           1       0.51      0.53      0.52       411\n",
      "           2       0.51      0.48      0.50       431\n",
      "           3       0.82      0.82      0.82       422\n",
      "           4       0.59      0.60      0.59       435\n",
      "           5       0.64      0.68      0.66       402\n",
      "\n",
      "    accuracy                           0.60      2541\n",
      "   macro avg       0.60      0.60      0.60      2541\n",
      "weighted avg       0.60      0.60      0.60      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_up_dt=AdaBoostClassifier(base_estimator=dt_up).fit(X_train2,y_train2)\n",
    "y_pred_ada_up_dt=ada_up_dt.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test2,y_pred_ada_up_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.602125147579693"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2,y_pred_ada_up_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using ensemble techniques the accuracy has increased as the algorithm mainly focuses on miss classifiers and learn their patterns of occcurances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       440\n",
      "           1       0.64      0.65      0.64       411\n",
      "           2       0.64      0.68      0.66       431\n",
      "           3       0.93      0.92      0.92       422\n",
      "           4       0.76      0.73      0.74       435\n",
      "           5       0.76      0.83      0.79       402\n",
      "\n",
      "    accuracy                           0.74      2541\n",
      "   macro avg       0.74      0.74      0.74      2541\n",
      "weighted avg       0.74      0.74      0.74      2541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_up_rf=AdaBoostClassifier(base_estimator=rf_up).fit(X_train2,y_train2)\n",
    "y_pred_ada_up_rf=ada_up_rf.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test2,y_pred_ada_up_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406532861078315"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2,y_pred_ada_up_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finally we can say adaboost classifier with random forest as the base esmitaor with over sampling has given the highest accuracy of 74% where as we see our base model gave the accuracy of 39%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The data set has 42 features and 5839 observations with the target column of 6 classes [0-5]\n",
    "\n",
    "2) the target class was imbalanced so, i compared models with both imabalanced data and then balanced data (SMOTE)\n",
    "\n",
    "3) As there are many features to decide our target column i applied various feature selection techniques\n",
    "    -forward selection\n",
    "    -Recurrsive feature elimination\n",
    "    -using correlation\n",
    "    -statiscal approach can be done but due to high dimensions i skipped it but we can use chisqaure test to know the significance.\n",
    "\n",
    "4) The feature selection techniques doesnt work well as there is heavy loss of information due to which model is unable to predict.\n",
    "\n",
    "5) To over come the dimentionality problem i have used PCA(Principle component analysis) and before applying it we need to scale the data as pca is a distance based method.\n",
    "\n",
    "6) After applying PCA with 16 components i could cover 95% of the data like it was a best technique to capture maximum data with less features.\n",
    "\n",
    "7) I have used k-fold cross validation with various model in it at a time passed the independent and dependant variables and with different performance measuring metrics Adaboost with base estimator gave best results.\n",
    "\n",
    "8) I have performed logistic ,decision tree,random forest, ada boost algorithms in predicting ffrom these adaboost gave highest accuracy of 55% .this is with imbalanced data.\n",
    "\n",
    "9) After doing imbalance treatment using SMOTE (over sampling) most the models performed well .\n",
    "\n",
    "10) highest accuracy with best scores in all metrics is from Adaboost classifierof 74% accuracy and Precision, recall was very high which makes model to learn hidden patterns to define each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
